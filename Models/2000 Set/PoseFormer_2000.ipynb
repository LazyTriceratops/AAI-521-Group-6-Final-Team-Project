{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyeLuW3-rzOO"
   },
   "source": [
    "# Poseformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPOmm5dyqM7-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4WFJGLdr5KP",
    "outputId": "34a446fa-7864-4f39-b466-3318789d5c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sJDqdpSvtUAu"
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/AAI-521/Final Project/Models/combined_dataset.pkl\")\n",
    "\n",
    "train_data = data[data['split'] == \"train\"]\n",
    "val_data = data[data['split'] == 'val']\n",
    "test_data = data[data['split'] == 'test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrgLc2DKuASl",
    "outputId": "34088dfb-e1de-4e66-fb07-74717f8f1e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: torch.Size([8313, 90, 33, 3]), torch.Size([8313])\n",
      "Val data: torch.Size([2253, 90, 33, 3]), torch.Size([2253])\n",
      "Test data: torch.Size([1414, 90, 33, 3]), torch.Size([1414])\n"
     ]
    }
   ],
   "source": [
    "# Extract padded_keypoints and label_index for each split\n",
    "def extract_data(split_data):\n",
    "    keypoints = np.stack(split_data['padded_keypoints'].values)  # Shape: [num_samples, 90, 33, 3]\n",
    "    labels = split_data['label_index'].values                   # Shape: [num_samples]\n",
    "    return keypoints, labels\n",
    "\n",
    "train_keypoints, train_labels = extract_data(train_data)\n",
    "val_keypoints, val_labels = extract_data(val_data)\n",
    "test_keypoints, test_labels = extract_data(test_data)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_keypoints = torch.tensor(train_keypoints, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "val_keypoints = torch.tensor(val_keypoints, dtype=torch.float32)\n",
    "val_labels = torch.tensor(val_labels, dtype=torch.long)\n",
    "\n",
    "test_keypoints = torch.tensor(test_keypoints, dtype=torch.float32)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "print(f\"Train data: {train_keypoints.shape}, {train_labels.shape}\")\n",
    "print(f\"Val data: {val_keypoints.shape}, {val_labels.shape}\")\n",
    "print(f\"Test data: {test_keypoints.shape}, {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jv2jLFWnvKmJ"
   },
   "outputs": [],
   "source": [
    "class PoseDataset(Dataset):\n",
    "    def __init__(self, keypoints, labels):\n",
    "        self.keypoints = keypoints\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        keypoint = self.keypoints[idx]  # Shape: [90, 33, 3]\n",
    "        label = self.labels[idx]       # Scalar\n",
    "        return keypoint, label\n",
    "\n",
    "\n",
    "train_dataset = PoseDataset(train_keypoints, train_labels)\n",
    "val_dataset = PoseDataset(val_keypoints, val_labels)\n",
    "test_dataset = PoseDataset(test_keypoints, test_labels)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TruN4s0UwP-K",
    "outputId": "f5317465-f9d6-47c3-fd67-1522c87f139f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "  Keypoints shape: torch.Size([32, 90, 33, 3])\n",
      "  Labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (keypoints, labels) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(f\"  Keypoints shape: {keypoints.shape}\")  # [batch_size, 90, 33, 3]\n",
    "    print(f\"  Labels shape: {labels.shape}\")        # [batch_size]\n",
    "    break  # Stop after the first batch for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMfHKs6m6oUd"
   },
   "source": [
    "## Custom Classes for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0I_kHnC9ymh"
   },
   "outputs": [],
   "source": [
    "class PoseFormer(nn.Module):\n",
    "    def __init__(self, num_keypoints=33, num_features=3, num_classes=2000, num_frames=90, embed_dim=128, num_heads=8, num_layers=4, dropout=0.1):\n",
    "        \"\"\"\n",
    "        PoseFormer implementation for video-based pose classification.\n",
    "\n",
    "        Args:\n",
    "            num_keypoints (int): Number of keypoints per frame.\n",
    "            num_features (int): Features per keypoint (e.g., x, y, z).\n",
    "            num_classes (int): Number of output classes.\n",
    "            num_frames (int): Fixed length of video sequences.\n",
    "            embed_dim (int): Embedding dimension for the transformer.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            num_layers (int): Number of transformer encoder layers.\n",
    "            dropout (float): Dropout rate.\n",
    "        \"\"\"\n",
    "        super(PoseFormer, self).__init__()\n",
    "        self.num_keypoints = num_keypoints\n",
    "        self.num_features = num_features\n",
    "        self.num_frames = num_frames\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Linear layer to embed keypoints into a higher-dimensional space\n",
    "        self.embedding = nn.Linear(num_keypoints * num_features, embed_dim)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(num_frames, embed_dim))\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for PoseFormer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, num_frames, num_keypoints, num_features).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Logits of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Flatten keypoints and features\n",
    "        x = x.view(batch_size, self.num_frames, -1)  # Shape: (batch_size, num_frames, num_keypoints * num_features)\n",
    "\n",
    "        # Apply embedding\n",
    "        x = self.embedding(x)  # Shape: (batch_size, num_frames, embed_dim)\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = x + self.positional_encoding.unsqueeze(0)  # Shape: (batch_size, num_frames, embed_dim)\n",
    "\n",
    "        # Permute for transformer (seq_len, batch_size, embed_dim)\n",
    "        x = x.permute(1, 0, 2)  # Shape: (num_frames, batch_size, embed_dim)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.transformer_encoder(x)  # Shape: (num_frames, batch_size, embed_dim)\n",
    "\n",
    "        # Take the mean over the temporal dimension\n",
    "        x = x.mean(dim=0)  # Shape: (batch_size, embed_dim)\n",
    "\n",
    "        # Classification\n",
    "        logits = self.classifier(x)  # Shape: (batch_size, num_classes)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T60h1j0G6kpR"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fxbw6Hw9yjF",
    "outputId": "0642a870-2831-4716-d0fe-f4832e617366"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = PoseFormer(num_keypoints=33, num_features=3, num_classes=2000, num_frames=90)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ao2T4nlW9ygt"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Training phase\n",
    "        for keypoints, labels in train_loader:\n",
    "            keypoints, labels = keypoints.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(keypoints)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Adjust learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "              f\"Train Acc: {100*correct/total:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for keypoints, labels in loader:\n",
    "            keypoints, labels = keypoints.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(keypoints)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eI09F00U9yeN",
    "outputId": "2251092c-9d0d-47e2-fc10-aeb3075cb6ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 7.6263, Train Acc: 0.07%, Val Loss: 7.6015, Val Acc: 0.04%\n",
      "Epoch [2/20], Loss: 7.5941, Train Acc: 0.08%, Val Loss: 7.6086, Val Acc: 0.09%\n",
      "Epoch [3/20], Loss: 7.5801, Train Acc: 0.12%, Val Loss: 7.6182, Val Acc: 0.04%\n",
      "Epoch [4/20], Loss: 7.5705, Train Acc: 0.11%, Val Loss: 7.6244, Val Acc: 0.09%\n",
      "Epoch [5/20], Loss: 7.5541, Train Acc: 0.10%, Val Loss: 7.6182, Val Acc: 0.04%\n",
      "Epoch [6/20], Loss: 7.4558, Train Acc: 0.16%, Val Loss: 7.4598, Val Acc: 0.00%\n",
      "Epoch [7/20], Loss: 7.2115, Train Acc: 0.18%, Val Loss: 7.3512, Val Acc: 0.18%\n",
      "Epoch [8/20], Loss: 7.0403, Train Acc: 0.19%, Val Loss: 7.3484, Val Acc: 0.27%\n",
      "Epoch [9/20], Loss: 6.9099, Train Acc: 0.28%, Val Loss: 7.3757, Val Acc: 0.44%\n",
      "Epoch [10/20], Loss: 6.8092, Train Acc: 0.26%, Val Loss: 7.4056, Val Acc: 0.27%\n",
      "Epoch [11/20], Loss: 6.6585, Train Acc: 0.59%, Val Loss: 7.4784, Val Acc: 0.27%\n",
      "Epoch [12/20], Loss: 6.6398, Train Acc: 0.67%, Val Loss: 7.4999, Val Acc: 0.27%\n",
      "Epoch [13/20], Loss: 6.6265, Train Acc: 0.72%, Val Loss: 7.4976, Val Acc: 0.27%\n",
      "Epoch [14/20], Loss: 6.6146, Train Acc: 0.71%, Val Loss: 7.5256, Val Acc: 0.36%\n",
      "Epoch [15/20], Loss: 6.6037, Train Acc: 0.70%, Val Loss: 7.5425, Val Acc: 0.27%\n",
      "Epoch [16/20], Loss: 6.5920, Train Acc: 0.66%, Val Loss: 7.5594, Val Acc: 0.31%\n",
      "Epoch [17/20], Loss: 6.5806, Train Acc: 0.81%, Val Loss: 7.5562, Val Acc: 0.31%\n",
      "Epoch [18/20], Loss: 6.5695, Train Acc: 0.76%, Val Loss: 7.5545, Val Acc: 0.31%\n",
      "Epoch [19/20], Loss: 6.5588, Train Acc: 0.77%, Val Loss: 7.5814, Val Acc: 0.31%\n",
      "Epoch [20/20], Loss: 6.5475, Train Acc: 0.78%, Val Loss: 7.6050, Val Acc: 0.36%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qkce14Sz9ybx",
    "outputId": "e147a3b7-d9be-497c-e5e4-b2f4d0087bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 7.6694, Test Accuracy: 0.14%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
