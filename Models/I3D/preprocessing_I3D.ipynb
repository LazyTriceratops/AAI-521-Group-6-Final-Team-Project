{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfNET4dfeQ9w"
   },
   "source": [
    "# I3D Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5171,
     "status": "ok",
     "timestamp": 1733417572360,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "LxZT7KBHeNJY"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import psutil\n",
    "import gc\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2910,
     "status": "ok",
     "timestamp": 1733417608057,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "xaB-a_jNfUIg"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "VIDEO_PATH = \"./DataSet/videos\"  # Path to raw videos\n",
    "SAVE_PATH = \"./DataSet/I3D_Processed\"  # Path to save processed .npy files\n",
    "METADATA_PATH = \"./DataSet/WLASL_v0.3.json\"  # Path to metadata\n",
    "TOP_100_PATH = \"./DataSet/gloss_counts_top_100.csv\"  # Path to top 100 glosses\n",
    "\n",
    "# Processing Parameters\n",
    "NUM_FRAMES = 64  # Fixed number of frames for each video\n",
    "FRAME_HEIGHT = 224  # Height for resizing frames\n",
    "FRAME_WIDTH = 224  # Width for resizing frames\n",
    "BATCH_SIZE = 5  # Batch size for loading frames to manage memory\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WLASL metadata\n",
    "with open(METADATA_PATH, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Map video IDs to gloss labels\n",
    "video_label_map = {}\n",
    "for entry in metadata:\n",
    "    label = entry['gloss']\n",
    "    for instance in entry['instances']:\n",
    "        video_id = int(instance['video_id'])\n",
    "        video_label_map[video_id] = label\n",
    "\n",
    "# Load top 100 glosses\n",
    "df = pd.read_csv(TOP_100_PATH)\n",
    "top_100_classes = df['Gloss'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_video(video_path, num_frames=NUM_FRAMES, target_size=(FRAME_HEIGHT, FRAME_WIDTH)):\n",
    "    \"\"\"Extract, resize, and pad/truncate frames from a video.\"\"\"\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        if frame_count == 0:\n",
    "            print(f\"Skipping video (no frames found): {video_path}\")\n",
    "            return None\n",
    "\n",
    "        # Sample frames uniformly\n",
    "        for i in range(min(num_frames, frame_count)):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, int(i * frame_count / num_frames))\n",
    "            success, frame = cap.read()\n",
    "            if success:\n",
    "                frame = cv2.resize(frame, target_size)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = frame.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "                frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Stack frames and pad if necessary\n",
    "        frames = np.stack(frames, axis=0)\n",
    "        if len(frames) < num_frames:\n",
    "            padding = np.zeros((num_frames - len(frames), *frames.shape[1:]))\n",
    "            frames = np.vstack([frames, padding])\n",
    "\n",
    "        return frames\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video {video_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_video(video_file):\n",
    "    \"\"\"Process a video and save the frames as .npy.\"\"\"\n",
    "    video_path = os.path.join(VIDEO_PATH, video_file)\n",
    "    video_id = int(video_file.split('.')[0])\n",
    "\n",
    "    if video_id in video_label_map:\n",
    "        label = video_label_map[video_id]\n",
    "    else:\n",
    "        print(f\"Warning: No label found for video {video_file}\")\n",
    "        return\n",
    "\n",
    "    frames = preprocess_video(video_path)\n",
    "    if frames is not None:\n",
    "        action_save_dir = os.path.join(SAVE_PATH, label)\n",
    "        os.makedirs(action_save_dir, exist_ok=True)\n",
    "        np.save(os.path.join(action_save_dir, f\"{video_id}_frames.npy\"), frames)\n",
    "        print(f\"Saved {video_file} as {label}_frames.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = [f for f in os.listdir(VIDEO_PATH) if f.endswith('.mp4')]\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(process_and_save_video, video_files), total=len(video_files), desc=\"Processing Videos\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1668856,
     "status": "ok",
     "timestamp": 1733419279070,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "TLi7LjzGfsW4",
    "outputId": "f4cec5b6-e967-4805-fb46-c8b6e1129286"
   },
   "outputs": [],
   "source": [
    "# Function to check memory usage\n",
    "def check_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Memory usage: {memory.percent}% of {memory.total / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "# Initialize variables\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Load data for top 100 glosses\n",
    "for action in tqdm(top_100_classes, desc=\"Loading data for top 100 classes\"):\n",
    "    action_dir = os.path.join(SAVE_PATH, action)\n",
    "\n",
    "    if os.path.exists(action_dir):\n",
    "        batch_sequences = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for video_file in os.listdir(action_dir):\n",
    "            if video_file.endswith('_frames.npy'):\n",
    "                frames = np.load(os.path.join(action_dir, video_file))\n",
    "                batch_sequences.append(frames)\n",
    "                batch_labels.append(action)\n",
    "\n",
    "                # Process in batches\n",
    "                if len(batch_sequences) == BATCH_SIZE:\n",
    "                    sequences.extend(batch_sequences)\n",
    "                    labels.extend(batch_labels)\n",
    "                    batch_sequences = []\n",
    "                    batch_labels = []\n",
    "                    check_memory()\n",
    "                    gc.collect()\n",
    "\n",
    "        # Process remaining videos\n",
    "        if batch_sequences:\n",
    "            sequences.extend(batch_sequences)\n",
    "            labels.extend(batch_labels)\n",
    "            check_memory()\n",
    "            gc.collect()\n",
    "    else:\n",
    "        print(f\"Missing directory for class: {action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "y = [top_100_classes.index(label) for label in labels]\n",
    "y = to_categorical(y, num_classes=len(top_100_classes))\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_FKncmjBsod"
   },
   "outputs": [],
   "source": [
    "np.save('./Dataset/final_Dataset/X_i3d_100.npy', X)\n",
    "np.save('./Dataset/final_Dataset/y_i3d_100.npy', y)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNShqWo1hG5RJNRFBXIBA6d",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1KYEW5zkMhtf70XWzkXLa7iK_L0sMjcOr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
