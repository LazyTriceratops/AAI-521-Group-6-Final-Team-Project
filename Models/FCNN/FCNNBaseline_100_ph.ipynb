{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LazyTriceratops/AAI-521-Group-6-Final-Team-Project/blob/HernandezModelTwo/FCNNBaseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ur3goNcm6Kg4",
    "outputId": "5adabfce-00e5-4e99-f701-f9dfe87c35b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[32mHernandezModelTwo\u001b[m\n",
      "  main\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# !git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUDwryWUlvw4",
    "outputId": "b1132e1f-0410-4931-d34e-36b1a64dfd11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AAI-521-Group-6-Final-Team-Project'...\n",
      "remote: Enumerating objects: 57, done.\u001b[K\n",
      "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Total 57 (delta 27), reused 37 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (57/57), 647.18 KiB | 2.21 MiB/s, done.\n",
      "Resolving deltas: 100% (27/27), done.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://Anitra-Hernandez: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@github.com/LazyTriceratops/AAI-521-Group-6-Final-Team-Project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-Emdz5G9hlH",
    "outputId": "1daeceb4-0b04-4370-ee48-edd530c689cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/AAI-521-Group-6-Final-Team-Project\n"
     ]
    }
   ],
   "source": [
    "# %cd AAI-521-Group-6-Final-Team-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9j9RbJsS9xYr",
    "outputId": "31b95d84-de3a-4f87-c3b3-00097b38a638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'HernandezModelTwo' set up to track remote branch 'HernandezModelTwo' from 'origin'.\n",
      "Switched to a new branch 'HernandezModelTwo'\n"
     ]
    }
   ],
   "source": [
    "# !git checkout HernandezModelTwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1733471414966,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "_KYp-v8c-X7v"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20096,
     "status": "ok",
     "timestamp": 1733469936429,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "3iDBLlph_kAf",
    "outputId": "01cec984-21ad-49f8-922f-56eeea9ae8bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10867,
     "status": "ok",
     "timestamp": 1733469985220,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "pIvr7sTg3G8c"
   },
   "outputs": [],
   "source": [
    "# Load processed data from disk\n",
    "save_path = '/content/drive/MyDrive/Colab Notebooks/AAI-521/Final Project/final_DataSet'\n",
    "\n",
    "X = np.load(os.path.join(save_path, 'X_mp_ph_100.npy'))\n",
    "y = np.load(os.path.join(save_path, 'y_mp_ph_100.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1733469996126,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "AtTI0l4p3G5z",
    "outputId": "899667bf-fda3-4447-fd94-e3ca5a98a60a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (896, 90, 258), y_train shape: (896, 100)\n",
      "X_val shape: (112, 90, 258), y_val shape: (112, 100)\n",
      "X_test shape: (112, 90, 258), y_test shape: (112, 100)\n"
     ]
    }
   ],
   "source": [
    "# Train-test-validation split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1733471607579,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "Na1wF3bm3uj7"
   },
   "outputs": [],
   "source": [
    "# Load the top 100 glosses\n",
    "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/AAI-521/Final Project/Models/MediaPipe_NoFace'\n",
    "top_100_path = '/content/drive/MyDrive/Colab Notebooks/AAI-521/Final Project/DataSet/gloss_counts_top_100.csv'\n",
    "df = pd.read_csv(top_100_path)\n",
    "top_100_classes = df['Gloss'].tolist()  # List of the top 100 glosses\n",
    "num_classes = 100\n",
    "\n",
    "# Label map for only top 100 glosses\n",
    "actions = sorted(os.listdir(DATA_PATH))\n",
    "label_map = {label: idx for idx, label in enumerate(actions) if label in top_100_classes}\n",
    "\n",
    "# Ensure the label map only contains the top 100\n",
    "label_map = {label: idx for idx, label in enumerate(top_100_classes)}  # Recreate the label map for top 100 only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1733471795497,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "YhqZ5vf56Zgn"
   },
   "outputs": [],
   "source": [
    "class PoseDataset(Dataset):\n",
    "    def __init__(self, keypoints, labels):\n",
    "        self.keypoints = keypoints  # Shape: [num_samples, 90, 258]\n",
    "        self.labels = labels        # Shape: [num_samples, 100]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        keypoint = self.keypoints[idx]  # Shape: [90, 258]\n",
    "\n",
    "        # Convert keypoint to tensor if it's not already a torch tensor\n",
    "        keypoint = torch.tensor(keypoint, dtype=torch.float32)  # Ensure tensor type is float32\n",
    "\n",
    "        # Check if the tensor is contiguous before applying view\n",
    "        if not keypoint.is_contiguous():\n",
    "            keypoint = keypoint.contiguous()\n",
    "\n",
    "        # Flatten the keypoint to a 1D vector: [90 * 258 = 23220]\n",
    "        keypoint = keypoint.view(-1)\n",
    "\n",
    "        label = self.labels[idx]  # Shape: [100], one-hot encoded label\n",
    "        return keypoint, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1733471797200,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "sjyECN7r6ZeV"
   },
   "outputs": [],
   "source": [
    "# Create DataLoaders using X and y\n",
    "batch_size = 32\n",
    "train_dataset = PoseDataset(X_train, y_train)\n",
    "val_dataset = PoseDataset(X_val, y_val)\n",
    "test_dataset = PoseDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1733471798563,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "ayDxx15g6Zb4"
   },
   "outputs": [],
   "source": [
    "# Define EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.stop_training = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1733471799671,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "MPPypgxr6ZZg"
   },
   "outputs": [],
   "source": [
    "# Define FCNNBaseline model\n",
    "class FCNNBaseline(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(FCNNBaseline, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)  # First fully connected layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)  # Regularization\n",
    "        self.fc2 = nn.Linear(512, num_classes)  # Output layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: [batch_size, input_dim]\n",
    "        x = self.fc1(x)  # [batch_size, 512]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1733472054704,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "X04Q0V7N6ZXD"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class indices\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Convert one-hot labels to class indices and compare\n",
    "        true_labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "        correct_preds += (predicted == true_labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct_preds / total_preds * 100\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class indices\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Convert one-hot labels to class indices and compare\n",
    "            true_labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            # Compare predicted class indices with the true labels\n",
    "            correct_preds += (predicted == true_labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = correct_preds / total_preds * 100\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1733472056486,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "QI5_bd5h6ZUk"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter search space\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-3, 5e-4, 1e-4],\n",
    "    'dropout_rate': [0.3, 0.5],  # Regularization\n",
    "    'weight_decay': [1e-5, 1e-4]  # L2 Regularization\n",
    "}\n",
    "\n",
    "# Function to train and evaluate with hyperparameters\n",
    "def train_and_evaluate_model(learning_rate, dropout_rate, weight_decay, num_classes):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize the model with the correct input_dim\n",
    "    model = FCNNBaseline(input_dim=90 * 258, num_classes=num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(50):  # Adjust as needed\n",
    "        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141925,
     "status": "ok",
     "timestamp": 1733472199517,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "lg41Ccnl3G3T",
    "outputId": "7b5e27a3-2ed2-404d-cd95-6ca0e95e45bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'weight_decay': 1e-05}\n",
      "Epoch 1: Train Loss: 5.0433, Train Acc: 1.00%, Val Loss: 4.5666, Val Acc: 1.79%\n",
      "Epoch 2: Train Loss: 4.5203, Train Acc: 2.46%, Val Loss: 4.5415, Val Acc: 3.57%\n",
      "Epoch 3: Train Loss: 4.4063, Train Acc: 1.67%, Val Loss: 4.4280, Val Acc: 0.89%\n",
      "Epoch 4: Train Loss: 4.2821, Train Acc: 2.57%, Val Loss: 4.4358, Val Acc: 1.79%\n",
      "Epoch 5: Train Loss: 4.2026, Train Acc: 2.79%, Val Loss: 4.4391, Val Acc: 0.89%\n",
      "Epoch 6: Train Loss: 4.1494, Train Acc: 3.01%, Val Loss: 4.4061, Val Acc: 1.79%\n",
      "Epoch 7: Train Loss: 4.0858, Train Acc: 4.35%, Val Loss: 4.3648, Val Acc: 1.79%\n",
      "Epoch 8: Train Loss: 4.0303, Train Acc: 4.24%, Val Loss: 4.3512, Val Acc: 1.79%\n",
      "Epoch 9: Train Loss: 4.0212, Train Acc: 3.46%, Val Loss: 4.3936, Val Acc: 1.79%\n",
      "Epoch 10: Train Loss: 3.9956, Train Acc: 5.58%, Val Loss: 4.4066, Val Acc: 0.89%\n",
      "Epoch 11: Train Loss: 3.9598, Train Acc: 4.69%, Val Loss: 4.3458, Val Acc: 2.68%\n",
      "Epoch 12: Train Loss: 3.9293, Train Acc: 5.80%, Val Loss: 4.3968, Val Acc: 0.89%\n",
      "Epoch 13: Train Loss: 3.9167, Train Acc: 4.91%, Val Loss: 4.3797, Val Acc: 1.79%\n",
      "Epoch 14: Train Loss: 3.8827, Train Acc: 5.80%, Val Loss: 4.4269, Val Acc: 1.79%\n",
      "Epoch 15: Train Loss: 3.8396, Train Acc: 6.81%, Val Loss: 4.3427, Val Acc: 3.57%\n",
      "Epoch 16: Train Loss: 3.7974, Train Acc: 6.58%, Val Loss: 4.4586, Val Acc: 0.89%\n",
      "Epoch 17: Train Loss: 3.7312, Train Acc: 7.59%, Val Loss: 4.3455, Val Acc: 2.68%\n",
      "Epoch 18: Train Loss: 3.7258, Train Acc: 8.15%, Val Loss: 4.3498, Val Acc: 3.57%\n",
      "Epoch 19: Train Loss: 3.6676, Train Acc: 7.48%, Val Loss: 4.3535, Val Acc: 4.46%\n",
      "Epoch 20: Train Loss: 3.6827, Train Acc: 7.92%, Val Loss: 4.4255, Val Acc: 2.68%\n",
      "Epoch 21: Train Loss: 3.6376, Train Acc: 9.93%, Val Loss: 4.3092, Val Acc: 8.04%\n",
      "Epoch 22: Train Loss: 3.5927, Train Acc: 8.48%, Val Loss: 4.3748, Val Acc: 6.25%\n",
      "Epoch 23: Train Loss: 3.6036, Train Acc: 8.82%, Val Loss: 4.4065, Val Acc: 4.46%\n",
      "Epoch 24: Train Loss: 3.5951, Train Acc: 9.71%, Val Loss: 4.3585, Val Acc: 3.57%\n",
      "Epoch 25: Train Loss: 3.6022, Train Acc: 10.49%, Val Loss: 4.3516, Val Acc: 4.46%\n",
      "Epoch 26: Train Loss: 3.5106, Train Acc: 11.05%, Val Loss: 4.3558, Val Acc: 8.04%\n",
      "Epoch 27: Train Loss: 3.4749, Train Acc: 11.50%, Val Loss: 4.3350, Val Acc: 7.14%\n",
      "Epoch 28: Train Loss: 3.4618, Train Acc: 10.71%, Val Loss: 4.3278, Val Acc: 8.04%\n",
      "Epoch 29: Train Loss: 3.4431, Train Acc: 11.05%, Val Loss: 4.2840, Val Acc: 5.36%\n",
      "Epoch 30: Train Loss: 3.4064, Train Acc: 12.17%, Val Loss: 4.4655, Val Acc: 4.46%\n",
      "Epoch 31: Train Loss: 3.4653, Train Acc: 11.61%, Val Loss: 4.3853, Val Acc: 7.14%\n",
      "Epoch 32: Train Loss: 3.3951, Train Acc: 12.61%, Val Loss: 4.3127, Val Acc: 8.93%\n",
      "Epoch 33: Train Loss: 3.3671, Train Acc: 10.49%, Val Loss: 4.3307, Val Acc: 8.93%\n",
      "Epoch 34: Train Loss: 3.3361, Train Acc: 13.06%, Val Loss: 4.2957, Val Acc: 8.04%\n",
      "Epoch 35: Train Loss: 3.3131, Train Acc: 13.06%, Val Loss: 4.3946, Val Acc: 8.04%\n",
      "Epoch 36: Train Loss: 3.2806, Train Acc: 13.39%, Val Loss: 4.2844, Val Acc: 9.82%\n",
      "Epoch 37: Train Loss: 3.3008, Train Acc: 13.50%, Val Loss: 4.3194, Val Acc: 10.71%\n",
      "Epoch 38: Train Loss: 3.2656, Train Acc: 12.17%, Val Loss: 4.4234, Val Acc: 10.71%\n",
      "Epoch 39: Train Loss: 3.2803, Train Acc: 14.62%, Val Loss: 4.4424, Val Acc: 8.93%\n",
      "Epoch 40: Train Loss: 3.1621, Train Acc: 14.06%, Val Loss: 4.4647, Val Acc: 9.82%\n",
      "Epoch 41: Train Loss: 3.1285, Train Acc: 16.63%, Val Loss: 4.5324, Val Acc: 8.93%\n",
      "Epoch 42: Train Loss: 3.1364, Train Acc: 16.96%, Val Loss: 4.3605, Val Acc: 9.82%\n",
      "Epoch 43: Train Loss: 3.2843, Train Acc: 12.39%, Val Loss: 4.2800, Val Acc: 10.71%\n",
      "Epoch 44: Train Loss: 3.1483, Train Acc: 18.30%, Val Loss: 4.4354, Val Acc: 10.71%\n",
      "Epoch 45: Train Loss: 3.1101, Train Acc: 15.85%, Val Loss: 4.4185, Val Acc: 10.71%\n",
      "Epoch 46: Train Loss: 3.0913, Train Acc: 17.86%, Val Loss: 4.4387, Val Acc: 11.61%\n",
      "Epoch 47: Train Loss: 3.1444, Train Acc: 16.52%, Val Loss: 4.4123, Val Acc: 9.82%\n",
      "Epoch 48: Train Loss: 3.0671, Train Acc: 18.42%, Val Loss: 4.4857, Val Acc: 11.61%\n",
      "Epoch 49: Train Loss: 3.0806, Train Acc: 17.30%, Val Loss: 4.4971, Val Acc: 9.82%\n",
      "Epoch 50: Train Loss: 3.0497, Train Acc: 15.29%, Val Loss: 4.5372, Val Acc: 11.61%\n",
      "Validation Loss: 11.6071\n",
      "Training with parameters: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'weight_decay': 0.0001}\n",
      "Epoch 1: Train Loss: 5.0007, Train Acc: 1.12%, Val Loss: 4.5497, Val Acc: 0.00%\n",
      "Epoch 2: Train Loss: 4.5258, Train Acc: 2.68%, Val Loss: 4.5469, Val Acc: 1.79%\n",
      "Epoch 3: Train Loss: 4.4062, Train Acc: 2.79%, Val Loss: 4.4329, Val Acc: 0.89%\n",
      "Epoch 4: Train Loss: 4.2812, Train Acc: 3.57%, Val Loss: 4.3724, Val Acc: 1.79%\n",
      "Epoch 5: Train Loss: 4.2309, Train Acc: 3.57%, Val Loss: 4.3718, Val Acc: 1.79%\n",
      "Epoch 6: Train Loss: 4.1432, Train Acc: 4.58%, Val Loss: 4.3593, Val Acc: 0.89%\n",
      "Epoch 7: Train Loss: 4.1006, Train Acc: 4.80%, Val Loss: 4.3834, Val Acc: 1.79%\n",
      "Epoch 8: Train Loss: 4.0607, Train Acc: 3.68%, Val Loss: 4.3625, Val Acc: 0.89%\n",
      "Epoch 9: Train Loss: 4.0123, Train Acc: 5.36%, Val Loss: 4.3760, Val Acc: 0.89%\n",
      "Epoch 10: Train Loss: 3.9885, Train Acc: 5.47%, Val Loss: 4.3357, Val Acc: 1.79%\n",
      "Epoch 11: Train Loss: 3.9276, Train Acc: 6.14%, Val Loss: 4.3698, Val Acc: 1.79%\n",
      "Epoch 12: Train Loss: 3.8831, Train Acc: 7.37%, Val Loss: 4.3746, Val Acc: 4.46%\n",
      "Epoch 13: Train Loss: 3.8410, Train Acc: 5.69%, Val Loss: 4.4257, Val Acc: 2.68%\n",
      "Epoch 14: Train Loss: 3.8113, Train Acc: 6.81%, Val Loss: 4.3344, Val Acc: 2.68%\n",
      "Epoch 15: Train Loss: 3.7665, Train Acc: 6.25%, Val Loss: 4.3969, Val Acc: 0.89%\n",
      "Epoch 16: Train Loss: 3.7366, Train Acc: 7.03%, Val Loss: 4.4168, Val Acc: 0.89%\n",
      "Epoch 17: Train Loss: 3.6733, Train Acc: 9.04%, Val Loss: 4.4084, Val Acc: 2.68%\n",
      "Epoch 18: Train Loss: 3.6483, Train Acc: 9.60%, Val Loss: 4.3121, Val Acc: 1.79%\n",
      "Epoch 19: Train Loss: 3.6519, Train Acc: 8.93%, Val Loss: 4.3150, Val Acc: 1.79%\n",
      "Epoch 20: Train Loss: 3.5997, Train Acc: 10.27%, Val Loss: 4.3594, Val Acc: 2.68%\n",
      "Epoch 21: Train Loss: 3.5558, Train Acc: 9.04%, Val Loss: 4.3209, Val Acc: 2.68%\n",
      "Epoch 22: Train Loss: 3.5826, Train Acc: 11.38%, Val Loss: 4.3190, Val Acc: 4.46%\n",
      "Epoch 23: Train Loss: 3.4876, Train Acc: 11.38%, Val Loss: 4.3809, Val Acc: 3.57%\n",
      "Epoch 24: Train Loss: 3.4748, Train Acc: 12.83%, Val Loss: 4.2968, Val Acc: 6.25%\n",
      "Epoch 25: Train Loss: 3.4651, Train Acc: 10.60%, Val Loss: 4.3460, Val Acc: 7.14%\n",
      "Epoch 26: Train Loss: 3.4590, Train Acc: 11.72%, Val Loss: 4.3962, Val Acc: 7.14%\n",
      "Epoch 27: Train Loss: 3.4192, Train Acc: 13.06%, Val Loss: 4.4582, Val Acc: 9.82%\n",
      "Epoch 28: Train Loss: 3.3980, Train Acc: 13.17%, Val Loss: 4.3928, Val Acc: 8.93%\n",
      "Epoch 29: Train Loss: 3.3706, Train Acc: 12.95%, Val Loss: 4.3583, Val Acc: 5.36%\n",
      "Epoch 30: Train Loss: 3.3440, Train Acc: 12.17%, Val Loss: 4.4212, Val Acc: 8.04%\n",
      "Epoch 31: Train Loss: 3.3277, Train Acc: 14.06%, Val Loss: 4.4287, Val Acc: 7.14%\n",
      "Epoch 32: Train Loss: 3.3245, Train Acc: 13.84%, Val Loss: 4.4148, Val Acc: 8.04%\n",
      "Epoch 33: Train Loss: 3.2913, Train Acc: 14.29%, Val Loss: 4.4211, Val Acc: 8.04%\n",
      "Epoch 34: Train Loss: 3.2444, Train Acc: 13.73%, Val Loss: 4.3213, Val Acc: 9.82%\n",
      "Epoch 35: Train Loss: 3.2457, Train Acc: 15.18%, Val Loss: 4.3090, Val Acc: 10.71%\n",
      "Epoch 36: Train Loss: 3.2529, Train Acc: 12.61%, Val Loss: 4.4295, Val Acc: 7.14%\n",
      "Epoch 37: Train Loss: 3.2157, Train Acc: 15.96%, Val Loss: 4.4269, Val Acc: 5.36%\n",
      "Epoch 38: Train Loss: 3.1800, Train Acc: 16.07%, Val Loss: 4.4702, Val Acc: 4.46%\n",
      "Epoch 39: Train Loss: 3.1565, Train Acc: 16.63%, Val Loss: 4.5785, Val Acc: 7.14%\n",
      "Epoch 40: Train Loss: 3.2022, Train Acc: 14.62%, Val Loss: 4.4881, Val Acc: 9.82%\n",
      "Epoch 41: Train Loss: 3.1197, Train Acc: 16.29%, Val Loss: 4.4980, Val Acc: 8.04%\n",
      "Epoch 42: Train Loss: 3.1463, Train Acc: 15.62%, Val Loss: 4.5368, Val Acc: 7.14%\n",
      "Epoch 43: Train Loss: 3.1544, Train Acc: 15.74%, Val Loss: 4.4614, Val Acc: 5.36%\n",
      "Epoch 44: Train Loss: 3.1411, Train Acc: 14.73%, Val Loss: 4.6139, Val Acc: 8.93%\n",
      "Epoch 45: Train Loss: 3.0782, Train Acc: 17.19%, Val Loss: 4.4031, Val Acc: 9.82%\n",
      "Epoch 46: Train Loss: 3.0495, Train Acc: 18.86%, Val Loss: 4.4863, Val Acc: 7.14%\n",
      "Epoch 47: Train Loss: 3.1207, Train Acc: 16.96%, Val Loss: 4.4490, Val Acc: 8.93%\n",
      "Epoch 48: Train Loss: 3.0298, Train Acc: 18.42%, Val Loss: 4.5865, Val Acc: 6.25%\n",
      "Epoch 49: Train Loss: 2.9586, Train Acc: 18.86%, Val Loss: 4.4648, Val Acc: 7.14%\n",
      "Epoch 50: Train Loss: 3.0230, Train Acc: 17.97%, Val Loss: 4.8369, Val Acc: 8.93%\n",
      "Validation Loss: 8.9286\n",
      "Training with parameters: {'dropout_rate': 0.3, 'learning_rate': 0.0005, 'weight_decay': 1e-05}\n",
      "Epoch 1: Train Loss: 4.8583, Train Acc: 1.34%, Val Loss: 4.6467, Val Acc: 0.00%\n",
      "Epoch 2: Train Loss: 4.5002, Train Acc: 1.45%, Val Loss: 4.5674, Val Acc: 0.89%\n",
      "Epoch 3: Train Loss: 4.3601, Train Acc: 2.01%, Val Loss: 4.5814, Val Acc: 0.00%\n",
      "Epoch 4: Train Loss: 4.2718, Train Acc: 2.23%, Val Loss: 4.4526, Val Acc: 0.89%\n",
      "Epoch 5: Train Loss: 4.1411, Train Acc: 5.25%, Val Loss: 4.5188, Val Acc: 0.89%\n",
      "Epoch 6: Train Loss: 4.0901, Train Acc: 5.92%, Val Loss: 4.4849, Val Acc: 2.68%\n",
      "Epoch 7: Train Loss: 4.0252, Train Acc: 5.69%, Val Loss: 4.4477, Val Acc: 0.89%\n",
      "Epoch 8: Train Loss: 3.9526, Train Acc: 6.58%, Val Loss: 4.4423, Val Acc: 1.79%\n",
      "Epoch 9: Train Loss: 3.9117, Train Acc: 5.92%, Val Loss: 4.4460, Val Acc: 1.79%\n",
      "Epoch 10: Train Loss: 3.8536, Train Acc: 7.70%, Val Loss: 4.5150, Val Acc: 3.57%\n",
      "Epoch 11: Train Loss: 3.8227, Train Acc: 7.25%, Val Loss: 4.4130, Val Acc: 0.89%\n",
      "Epoch 12: Train Loss: 3.7444, Train Acc: 9.26%, Val Loss: 4.4719, Val Acc: 3.57%\n",
      "Epoch 13: Train Loss: 3.6664, Train Acc: 9.26%, Val Loss: 4.4755, Val Acc: 3.57%\n",
      "Epoch 14: Train Loss: 3.6417, Train Acc: 9.82%, Val Loss: 4.4568, Val Acc: 1.79%\n",
      "Epoch 15: Train Loss: 3.5674, Train Acc: 12.83%, Val Loss: 4.3970, Val Acc: 3.57%\n",
      "Epoch 16: Train Loss: 3.5181, Train Acc: 13.06%, Val Loss: 4.5364, Val Acc: 1.79%\n",
      "Epoch 17: Train Loss: 3.4569, Train Acc: 14.40%, Val Loss: 4.3438, Val Acc: 5.36%\n",
      "Epoch 18: Train Loss: 3.3721, Train Acc: 16.52%, Val Loss: 4.4664, Val Acc: 2.68%\n",
      "Epoch 19: Train Loss: 3.3333, Train Acc: 15.40%, Val Loss: 4.4297, Val Acc: 3.57%\n",
      "Epoch 20: Train Loss: 3.2638, Train Acc: 14.73%, Val Loss: 4.3753, Val Acc: 6.25%\n",
      "Epoch 21: Train Loss: 3.2369, Train Acc: 16.07%, Val Loss: 4.3957, Val Acc: 4.46%\n",
      "Epoch 22: Train Loss: 3.1936, Train Acc: 17.41%, Val Loss: 4.3271, Val Acc: 6.25%\n",
      "Epoch 23: Train Loss: 3.1358, Train Acc: 19.31%, Val Loss: 4.4897, Val Acc: 4.46%\n",
      "Epoch 24: Train Loss: 3.0929, Train Acc: 17.97%, Val Loss: 4.4361, Val Acc: 4.46%\n",
      "Epoch 25: Train Loss: 3.0649, Train Acc: 19.20%, Val Loss: 4.4369, Val Acc: 3.57%\n",
      "Epoch 26: Train Loss: 2.9960, Train Acc: 19.87%, Val Loss: 4.3589, Val Acc: 7.14%\n",
      "Epoch 27: Train Loss: 2.9499, Train Acc: 22.54%, Val Loss: 4.5408, Val Acc: 6.25%\n",
      "Epoch 28: Train Loss: 2.9158, Train Acc: 23.21%, Val Loss: 4.3984, Val Acc: 7.14%\n",
      "Epoch 29: Train Loss: 2.8783, Train Acc: 22.88%, Val Loss: 4.4639, Val Acc: 8.04%\n",
      "Epoch 30: Train Loss: 2.8587, Train Acc: 23.55%, Val Loss: 4.3900, Val Acc: 8.93%\n",
      "Epoch 31: Train Loss: 2.8130, Train Acc: 24.44%, Val Loss: 4.4792, Val Acc: 8.93%\n",
      "Epoch 32: Train Loss: 2.7208, Train Acc: 27.34%, Val Loss: 4.4994, Val Acc: 6.25%\n",
      "Epoch 33: Train Loss: 2.7092, Train Acc: 27.34%, Val Loss: 4.4107, Val Acc: 8.04%\n",
      "Epoch 34: Train Loss: 2.6441, Train Acc: 28.12%, Val Loss: 4.4810, Val Acc: 8.04%\n",
      "Epoch 35: Train Loss: 2.5906, Train Acc: 29.80%, Val Loss: 4.4779, Val Acc: 6.25%\n",
      "Epoch 36: Train Loss: 2.5730, Train Acc: 29.58%, Val Loss: 4.5575, Val Acc: 5.36%\n",
      "Epoch 37: Train Loss: 2.5381, Train Acc: 30.13%, Val Loss: 4.5583, Val Acc: 7.14%\n",
      "Epoch 38: Train Loss: 2.5403, Train Acc: 32.48%, Val Loss: 4.5013, Val Acc: 6.25%\n",
      "Epoch 39: Train Loss: 2.4626, Train Acc: 32.14%, Val Loss: 4.5893, Val Acc: 7.14%\n",
      "Epoch 40: Train Loss: 2.4504, Train Acc: 33.37%, Val Loss: 4.4921, Val Acc: 8.93%\n",
      "Epoch 41: Train Loss: 2.4230, Train Acc: 33.71%, Val Loss: 4.6340, Val Acc: 8.04%\n",
      "Epoch 42: Train Loss: 2.3442, Train Acc: 35.16%, Val Loss: 4.6399, Val Acc: 8.93%\n",
      "Epoch 43: Train Loss: 2.3731, Train Acc: 34.26%, Val Loss: 4.6608, Val Acc: 6.25%\n",
      "Epoch 44: Train Loss: 2.3262, Train Acc: 39.06%, Val Loss: 4.5992, Val Acc: 8.93%\n",
      "Epoch 45: Train Loss: 2.2768, Train Acc: 37.83%, Val Loss: 4.6607, Val Acc: 6.25%\n",
      "Epoch 46: Train Loss: 2.2161, Train Acc: 37.95%, Val Loss: 4.7149, Val Acc: 5.36%\n",
      "Epoch 47: Train Loss: 2.1856, Train Acc: 40.18%, Val Loss: 4.6602, Val Acc: 6.25%\n",
      "Epoch 48: Train Loss: 2.1926, Train Acc: 38.62%, Val Loss: 4.7316, Val Acc: 10.71%\n",
      "Epoch 49: Train Loss: 2.1707, Train Acc: 38.84%, Val Loss: 4.7793, Val Acc: 8.04%\n",
      "Epoch 50: Train Loss: 2.1493, Train Acc: 40.85%, Val Loss: 4.7346, Val Acc: 6.25%\n",
      "Validation Loss: 6.2500\n",
      "Training with parameters: {'dropout_rate': 0.3, 'learning_rate': 0.0005, 'weight_decay': 0.0001}\n",
      "Epoch 1: Train Loss: 4.8743, Train Acc: 1.34%, Val Loss: 4.6494, Val Acc: 0.00%\n",
      "Epoch 2: Train Loss: 4.5429, Train Acc: 1.45%, Val Loss: 4.5857, Val Acc: 1.79%\n",
      "Epoch 3: Train Loss: 4.4181, Train Acc: 3.12%, Val Loss: 4.5373, Val Acc: 0.89%\n",
      "Epoch 4: Train Loss: 4.3228, Train Acc: 4.69%, Val Loss: 4.5426, Val Acc: 0.89%\n",
      "Epoch 5: Train Loss: 4.1984, Train Acc: 4.46%, Val Loss: 4.4918, Val Acc: 0.89%\n",
      "Epoch 6: Train Loss: 4.1286, Train Acc: 3.91%, Val Loss: 4.4861, Val Acc: 0.89%\n",
      "Epoch 7: Train Loss: 4.0404, Train Acc: 5.25%, Val Loss: 4.4797, Val Acc: 0.89%\n",
      "Epoch 8: Train Loss: 3.9832, Train Acc: 6.14%, Val Loss: 4.4592, Val Acc: 0.89%\n",
      "Epoch 9: Train Loss: 3.9381, Train Acc: 6.14%, Val Loss: 4.4492, Val Acc: 1.79%\n",
      "Epoch 10: Train Loss: 3.9228, Train Acc: 5.80%, Val Loss: 4.4361, Val Acc: 2.68%\n",
      "Epoch 11: Train Loss: 3.8341, Train Acc: 8.82%, Val Loss: 4.4059, Val Acc: 0.89%\n",
      "Epoch 12: Train Loss: 3.7798, Train Acc: 9.26%, Val Loss: 4.4576, Val Acc: 1.79%\n",
      "Epoch 13: Train Loss: 3.7329, Train Acc: 9.71%, Val Loss: 4.4419, Val Acc: 1.79%\n",
      "Epoch 14: Train Loss: 3.7014, Train Acc: 10.60%, Val Loss: 4.4319, Val Acc: 3.57%\n",
      "Epoch 15: Train Loss: 3.6038, Train Acc: 10.27%, Val Loss: 4.4774, Val Acc: 0.89%\n",
      "Epoch 16: Train Loss: 3.5497, Train Acc: 13.39%, Val Loss: 4.4708, Val Acc: 4.46%\n",
      "Epoch 17: Train Loss: 3.5368, Train Acc: 10.60%, Val Loss: 4.4523, Val Acc: 2.68%\n",
      "Epoch 18: Train Loss: 3.4486, Train Acc: 13.17%, Val Loss: 4.3851, Val Acc: 4.46%\n",
      "Epoch 19: Train Loss: 3.4185, Train Acc: 13.50%, Val Loss: 4.4586, Val Acc: 6.25%\n",
      "Epoch 20: Train Loss: 3.3797, Train Acc: 15.96%, Val Loss: 4.4707, Val Acc: 5.36%\n",
      "Epoch 21: Train Loss: 3.3126, Train Acc: 14.73%, Val Loss: 4.4869, Val Acc: 1.79%\n",
      "Epoch 22: Train Loss: 3.2873, Train Acc: 16.18%, Val Loss: 4.4814, Val Acc: 7.14%\n",
      "Epoch 23: Train Loss: 3.1747, Train Acc: 19.64%, Val Loss: 4.5588, Val Acc: 4.46%\n",
      "Epoch 24: Train Loss: 3.1806, Train Acc: 16.96%, Val Loss: 4.5063, Val Acc: 5.36%\n",
      "Epoch 25: Train Loss: 3.0726, Train Acc: 19.64%, Val Loss: 4.4863, Val Acc: 8.04%\n",
      "Epoch 26: Train Loss: 3.0754, Train Acc: 19.20%, Val Loss: 4.4732, Val Acc: 8.04%\n",
      "Epoch 27: Train Loss: 2.9918, Train Acc: 21.32%, Val Loss: 4.3830, Val Acc: 6.25%\n",
      "Epoch 28: Train Loss: 3.0178, Train Acc: 20.76%, Val Loss: 4.4275, Val Acc: 7.14%\n",
      "Epoch 29: Train Loss: 2.9096, Train Acc: 23.55%, Val Loss: 4.4114, Val Acc: 11.61%\n",
      "Epoch 30: Train Loss: 2.8969, Train Acc: 23.88%, Val Loss: 4.4831, Val Acc: 8.04%\n",
      "Epoch 31: Train Loss: 2.8647, Train Acc: 23.66%, Val Loss: 4.4828, Val Acc: 5.36%\n",
      "Epoch 32: Train Loss: 2.8534, Train Acc: 22.77%, Val Loss: 4.5401, Val Acc: 8.93%\n",
      "Epoch 33: Train Loss: 2.7697, Train Acc: 25.89%, Val Loss: 4.5063, Val Acc: 10.71%\n",
      "Epoch 34: Train Loss: 2.7085, Train Acc: 28.01%, Val Loss: 4.6279, Val Acc: 7.14%\n",
      "Epoch 35: Train Loss: 2.7239, Train Acc: 27.34%, Val Loss: 4.5877, Val Acc: 8.93%\n",
      "Epoch 36: Train Loss: 2.6138, Train Acc: 26.56%, Val Loss: 4.6230, Val Acc: 5.36%\n",
      "Epoch 37: Train Loss: 2.5985, Train Acc: 29.24%, Val Loss: 4.4695, Val Acc: 12.50%\n",
      "Epoch 38: Train Loss: 2.6044, Train Acc: 28.79%, Val Loss: 4.5666, Val Acc: 10.71%\n",
      "Epoch 39: Train Loss: 2.5391, Train Acc: 31.03%, Val Loss: 4.5851, Val Acc: 9.82%\n",
      "Epoch 40: Train Loss: 2.4454, Train Acc: 33.04%, Val Loss: 4.6042, Val Acc: 11.61%\n",
      "Epoch 41: Train Loss: 2.4050, Train Acc: 32.59%, Val Loss: 4.7385, Val Acc: 8.04%\n",
      "Epoch 42: Train Loss: 2.4645, Train Acc: 31.58%, Val Loss: 4.5642, Val Acc: 11.61%\n",
      "Epoch 43: Train Loss: 2.4024, Train Acc: 33.26%, Val Loss: 4.5049, Val Acc: 13.39%\n",
      "Epoch 44: Train Loss: 2.3876, Train Acc: 34.04%, Val Loss: 4.7325, Val Acc: 9.82%\n",
      "Epoch 45: Train Loss: 2.3687, Train Acc: 34.60%, Val Loss: 4.6220, Val Acc: 9.82%\n",
      "Epoch 46: Train Loss: 2.2873, Train Acc: 35.83%, Val Loss: 4.5859, Val Acc: 14.29%\n",
      "Epoch 47: Train Loss: 2.3134, Train Acc: 36.38%, Val Loss: 4.6419, Val Acc: 11.61%\n",
      "Epoch 48: Train Loss: 2.2464, Train Acc: 36.50%, Val Loss: 4.7645, Val Acc: 13.39%\n",
      "Epoch 49: Train Loss: 2.2029, Train Acc: 38.06%, Val Loss: 4.7315, Val Acc: 15.18%\n",
      "Epoch 50: Train Loss: 2.2178, Train Acc: 37.72%, Val Loss: 4.6079, Val Acc: 13.39%\n",
      "Validation Loss: 13.3929\n",
      "Training with parameters: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'weight_decay': 1e-05}\n",
      "Epoch 1: Train Loss: 4.6497, Train Acc: 1.23%, Val Loss: 4.6511, Val Acc: 0.00%\n",
      "Epoch 2: Train Loss: 4.5293, Train Acc: 2.68%, Val Loss: 4.6566, Val Acc: 0.00%\n",
      "Epoch 3: Train Loss: 4.4592, Train Acc: 2.79%, Val Loss: 4.6226, Val Acc: 0.89%\n",
      "Epoch 4: Train Loss: 4.4154, Train Acc: 3.24%, Val Loss: 4.5855, Val Acc: 0.00%\n",
      "Epoch 5: Train Loss: 4.3434, Train Acc: 4.13%, Val Loss: 4.5678, Val Acc: 0.89%\n",
      "Epoch 6: Train Loss: 4.2699, Train Acc: 5.02%, Val Loss: 4.5323, Val Acc: 0.89%\n",
      "Epoch 7: Train Loss: 4.2195, Train Acc: 5.47%, Val Loss: 4.5442, Val Acc: 1.79%\n",
      "Epoch 8: Train Loss: 4.1730, Train Acc: 4.80%, Val Loss: 4.4972, Val Acc: 0.89%\n",
      "Epoch 9: Train Loss: 4.1073, Train Acc: 6.92%, Val Loss: 4.4975, Val Acc: 1.79%\n",
      "Epoch 10: Train Loss: 4.0495, Train Acc: 5.69%, Val Loss: 4.4494, Val Acc: 0.89%\n",
      "Epoch 11: Train Loss: 4.0461, Train Acc: 7.59%, Val Loss: 4.4413, Val Acc: 0.89%\n",
      "Epoch 12: Train Loss: 3.9824, Train Acc: 6.58%, Val Loss: 4.4319, Val Acc: 0.89%\n",
      "Epoch 13: Train Loss: 3.9261, Train Acc: 9.04%, Val Loss: 4.4447, Val Acc: 1.79%\n",
      "Epoch 14: Train Loss: 3.8813, Train Acc: 10.04%, Val Loss: 4.4286, Val Acc: 1.79%\n",
      "Epoch 15: Train Loss: 3.8611, Train Acc: 8.37%, Val Loss: 4.4111, Val Acc: 2.68%\n",
      "Epoch 16: Train Loss: 3.8488, Train Acc: 10.83%, Val Loss: 4.3885, Val Acc: 1.79%\n",
      "Epoch 17: Train Loss: 3.8426, Train Acc: 10.38%, Val Loss: 4.3877, Val Acc: 2.68%\n",
      "Epoch 18: Train Loss: 3.7640, Train Acc: 10.49%, Val Loss: 4.4047, Val Acc: 4.46%\n",
      "Epoch 19: Train Loss: 3.7371, Train Acc: 11.16%, Val Loss: 4.3697, Val Acc: 4.46%\n",
      "Epoch 20: Train Loss: 3.7113, Train Acc: 12.72%, Val Loss: 4.3935, Val Acc: 1.79%\n",
      "Epoch 21: Train Loss: 3.6827, Train Acc: 11.27%, Val Loss: 4.3580, Val Acc: 2.68%\n",
      "Epoch 22: Train Loss: 3.6407, Train Acc: 11.05%, Val Loss: 4.3639, Val Acc: 0.89%\n",
      "Epoch 23: Train Loss: 3.6385, Train Acc: 12.39%, Val Loss: 4.3479, Val Acc: 4.46%\n",
      "Epoch 24: Train Loss: 3.5852, Train Acc: 13.28%, Val Loss: 4.3211, Val Acc: 5.36%\n",
      "Epoch 25: Train Loss: 3.5810, Train Acc: 12.61%, Val Loss: 4.3197, Val Acc: 3.57%\n",
      "Epoch 26: Train Loss: 3.5638, Train Acc: 13.17%, Val Loss: 4.3283, Val Acc: 4.46%\n",
      "Epoch 27: Train Loss: 3.5525, Train Acc: 13.62%, Val Loss: 4.3216, Val Acc: 4.46%\n",
      "Epoch 28: Train Loss: 3.4665, Train Acc: 16.74%, Val Loss: 4.3536, Val Acc: 1.79%\n",
      "Epoch 29: Train Loss: 3.4601, Train Acc: 16.29%, Val Loss: 4.3102, Val Acc: 4.46%\n",
      "Epoch 30: Train Loss: 3.4205, Train Acc: 18.64%, Val Loss: 4.3102, Val Acc: 2.68%\n",
      "Epoch 31: Train Loss: 3.3986, Train Acc: 17.63%, Val Loss: 4.3274, Val Acc: 4.46%\n",
      "Epoch 32: Train Loss: 3.3417, Train Acc: 19.42%, Val Loss: 4.2822, Val Acc: 4.46%\n",
      "Epoch 33: Train Loss: 3.3311, Train Acc: 20.42%, Val Loss: 4.3027, Val Acc: 4.46%\n",
      "Epoch 34: Train Loss: 3.3460, Train Acc: 17.86%, Val Loss: 4.2879, Val Acc: 4.46%\n",
      "Epoch 35: Train Loss: 3.2674, Train Acc: 20.65%, Val Loss: 4.2777, Val Acc: 3.57%\n",
      "Epoch 36: Train Loss: 3.2641, Train Acc: 19.08%, Val Loss: 4.2860, Val Acc: 5.36%\n",
      "Epoch 37: Train Loss: 3.1979, Train Acc: 22.54%, Val Loss: 4.2513, Val Acc: 4.46%\n",
      "Epoch 38: Train Loss: 3.2066, Train Acc: 19.98%, Val Loss: 4.2707, Val Acc: 5.36%\n",
      "Epoch 39: Train Loss: 3.1378, Train Acc: 22.88%, Val Loss: 4.2517, Val Acc: 6.25%\n",
      "Epoch 40: Train Loss: 3.1162, Train Acc: 24.89%, Val Loss: 4.3000, Val Acc: 4.46%\n",
      "Epoch 41: Train Loss: 3.0869, Train Acc: 24.78%, Val Loss: 4.2646, Val Acc: 3.57%\n",
      "Epoch 42: Train Loss: 3.1110, Train Acc: 24.00%, Val Loss: 4.2795, Val Acc: 5.36%\n",
      "Epoch 43: Train Loss: 3.0747, Train Acc: 23.66%, Val Loss: 4.2725, Val Acc: 5.36%\n",
      "Epoch 44: Train Loss: 2.9970, Train Acc: 26.23%, Val Loss: 4.2830, Val Acc: 4.46%\n",
      "Epoch 45: Train Loss: 2.9796, Train Acc: 27.90%, Val Loss: 4.2562, Val Acc: 6.25%\n",
      "Epoch 46: Train Loss: 2.9911, Train Acc: 25.33%, Val Loss: 4.2779, Val Acc: 5.36%\n",
      "Epoch 47: Train Loss: 2.9425, Train Acc: 28.35%, Val Loss: 4.2556, Val Acc: 7.14%\n",
      "Epoch 48: Train Loss: 2.9429, Train Acc: 26.45%, Val Loss: 4.2495, Val Acc: 6.25%\n",
      "Epoch 49: Train Loss: 2.9135, Train Acc: 27.90%, Val Loss: 4.2213, Val Acc: 6.25%\n",
      "Epoch 50: Train Loss: 2.8738, Train Acc: 30.47%, Val Loss: 4.2813, Val Acc: 4.46%\n",
      "Validation Loss: 4.4643\n",
      "Training with parameters: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'weight_decay': 0.0001}\n",
      "Epoch 1: Train Loss: 4.6608, Train Acc: 0.89%, Val Loss: 4.6401, Val Acc: 0.89%\n",
      "Epoch 2: Train Loss: 4.5555, Train Acc: 2.46%, Val Loss: 4.6135, Val Acc: 1.79%\n",
      "Epoch 3: Train Loss: 4.5123, Train Acc: 3.01%, Val Loss: 4.6146, Val Acc: 2.68%\n",
      "Epoch 4: Train Loss: 4.4594, Train Acc: 3.91%, Val Loss: 4.5879, Val Acc: 0.89%\n",
      "Epoch 5: Train Loss: 4.3944, Train Acc: 3.68%, Val Loss: 4.5693, Val Acc: 1.79%\n",
      "Epoch 6: Train Loss: 4.3311, Train Acc: 4.02%, Val Loss: 4.5413, Val Acc: 0.89%\n",
      "Epoch 7: Train Loss: 4.2719, Train Acc: 5.25%, Val Loss: 4.5022, Val Acc: 2.68%\n",
      "Epoch 8: Train Loss: 4.2198, Train Acc: 6.14%, Val Loss: 4.4929, Val Acc: 1.79%\n",
      "Epoch 9: Train Loss: 4.1730, Train Acc: 4.69%, Val Loss: 4.4775, Val Acc: 1.79%\n",
      "Epoch 10: Train Loss: 4.1181, Train Acc: 5.25%, Val Loss: 4.4537, Val Acc: 1.79%\n",
      "Epoch 11: Train Loss: 4.0753, Train Acc: 6.70%, Val Loss: 4.4295, Val Acc: 2.68%\n",
      "Epoch 12: Train Loss: 4.0305, Train Acc: 7.14%, Val Loss: 4.4052, Val Acc: 2.68%\n",
      "Epoch 13: Train Loss: 3.9847, Train Acc: 8.26%, Val Loss: 4.4064, Val Acc: 2.68%\n",
      "Epoch 14: Train Loss: 3.9423, Train Acc: 7.37%, Val Loss: 4.4085, Val Acc: 2.68%\n",
      "Epoch 15: Train Loss: 3.9108, Train Acc: 9.38%, Val Loss: 4.3869, Val Acc: 2.68%\n",
      "Epoch 16: Train Loss: 3.8794, Train Acc: 8.04%, Val Loss: 4.3645, Val Acc: 4.46%\n",
      "Epoch 17: Train Loss: 3.8580, Train Acc: 9.49%, Val Loss: 4.3608, Val Acc: 3.57%\n",
      "Epoch 18: Train Loss: 3.8307, Train Acc: 8.59%, Val Loss: 4.3755, Val Acc: 1.79%\n",
      "Epoch 19: Train Loss: 3.7745, Train Acc: 10.16%, Val Loss: 4.3534, Val Acc: 3.57%\n",
      "Epoch 20: Train Loss: 3.7683, Train Acc: 10.83%, Val Loss: 4.3493, Val Acc: 3.57%\n",
      "Epoch 21: Train Loss: 3.6889, Train Acc: 12.50%, Val Loss: 4.3603, Val Acc: 3.57%\n",
      "Epoch 22: Train Loss: 3.7044, Train Acc: 11.72%, Val Loss: 4.3635, Val Acc: 3.57%\n",
      "Epoch 23: Train Loss: 3.6419, Train Acc: 11.94%, Val Loss: 4.3705, Val Acc: 3.57%\n",
      "Epoch 24: Train Loss: 3.6781, Train Acc: 11.61%, Val Loss: 4.3310, Val Acc: 4.46%\n",
      "Epoch 25: Train Loss: 3.6466, Train Acc: 14.17%, Val Loss: 4.3149, Val Acc: 4.46%\n",
      "Epoch 26: Train Loss: 3.5663, Train Acc: 15.18%, Val Loss: 4.3515, Val Acc: 3.57%\n",
      "Epoch 27: Train Loss: 3.5307, Train Acc: 15.85%, Val Loss: 4.3337, Val Acc: 4.46%\n",
      "Epoch 28: Train Loss: 3.5260, Train Acc: 16.29%, Val Loss: 4.3412, Val Acc: 3.57%\n",
      "Epoch 29: Train Loss: 3.4998, Train Acc: 14.17%, Val Loss: 4.3405, Val Acc: 3.57%\n",
      "Epoch 30: Train Loss: 3.4839, Train Acc: 15.51%, Val Loss: 4.3176, Val Acc: 5.36%\n",
      "Epoch 31: Train Loss: 3.4744, Train Acc: 16.52%, Val Loss: 4.3097, Val Acc: 4.46%\n",
      "Epoch 32: Train Loss: 3.4229, Train Acc: 18.75%, Val Loss: 4.3186, Val Acc: 5.36%\n",
      "Epoch 33: Train Loss: 3.3929, Train Acc: 17.86%, Val Loss: 4.3152, Val Acc: 6.25%\n",
      "Epoch 34: Train Loss: 3.3602, Train Acc: 18.75%, Val Loss: 4.3063, Val Acc: 4.46%\n",
      "Epoch 35: Train Loss: 3.3268, Train Acc: 20.20%, Val Loss: 4.2794, Val Acc: 4.46%\n",
      "Epoch 36: Train Loss: 3.3242, Train Acc: 18.19%, Val Loss: 4.3018, Val Acc: 6.25%\n",
      "Epoch 37: Train Loss: 3.2775, Train Acc: 21.54%, Val Loss: 4.2872, Val Acc: 6.25%\n",
      "Epoch 38: Train Loss: 3.2376, Train Acc: 22.54%, Val Loss: 4.3247, Val Acc: 6.25%\n",
      "Epoch 39: Train Loss: 3.2139, Train Acc: 21.88%, Val Loss: 4.3391, Val Acc: 5.36%\n",
      "Epoch 40: Train Loss: 3.2337, Train Acc: 21.32%, Val Loss: 4.2957, Val Acc: 7.14%\n",
      "Epoch 41: Train Loss: 3.2103, Train Acc: 21.09%, Val Loss: 4.2917, Val Acc: 4.46%\n",
      "Epoch 42: Train Loss: 3.1335, Train Acc: 23.21%, Val Loss: 4.3060, Val Acc: 6.25%\n",
      "Epoch 43: Train Loss: 3.1478, Train Acc: 21.65%, Val Loss: 4.2934, Val Acc: 4.46%\n",
      "Epoch 44: Train Loss: 3.1285, Train Acc: 23.66%, Val Loss: 4.3251, Val Acc: 4.46%\n",
      "Epoch 45: Train Loss: 3.1057, Train Acc: 22.88%, Val Loss: 4.3235, Val Acc: 5.36%\n",
      "Epoch 46: Train Loss: 3.0457, Train Acc: 26.90%, Val Loss: 4.2877, Val Acc: 5.36%\n",
      "Epoch 47: Train Loss: 3.0082, Train Acc: 26.34%, Val Loss: 4.2839, Val Acc: 7.14%\n",
      "Epoch 48: Train Loss: 3.0107, Train Acc: 27.01%, Val Loss: 4.3207, Val Acc: 4.46%\n",
      "Epoch 49: Train Loss: 3.0026, Train Acc: 25.56%, Val Loss: 4.2709, Val Acc: 7.14%\n",
      "Epoch 50: Train Loss: 2.9640, Train Acc: 27.46%, Val Loss: 4.2704, Val Acc: 3.57%\n",
      "Validation Loss: 3.5714\n",
      "Training with parameters: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'weight_decay': 1e-05}\n",
      "Epoch 1: Train Loss: 5.0349, Train Acc: 1.45%, Val Loss: 4.6516, Val Acc: 0.00%\n",
      "Epoch 2: Train Loss: 4.5401, Train Acc: 2.01%, Val Loss: 4.6317, Val Acc: 0.89%\n",
      "Epoch 3: Train Loss: 4.4061, Train Acc: 3.12%, Val Loss: 4.5004, Val Acc: 0.89%\n",
      "Epoch 4: Train Loss: 4.2770, Train Acc: 3.46%, Val Loss: 4.4831, Val Acc: 0.89%\n",
      "Epoch 5: Train Loss: 4.1615, Train Acc: 3.35%, Val Loss: 4.4751, Val Acc: 0.00%\n",
      "Epoch 6: Train Loss: 4.1534, Train Acc: 3.91%, Val Loss: 4.4938, Val Acc: 1.79%\n",
      "Epoch 7: Train Loss: 4.0927, Train Acc: 4.13%, Val Loss: 4.3665, Val Acc: 0.00%\n",
      "Epoch 8: Train Loss: 4.0320, Train Acc: 5.69%, Val Loss: 4.4144, Val Acc: 0.89%\n",
      "Epoch 9: Train Loss: 3.9730, Train Acc: 5.13%, Val Loss: 4.4219, Val Acc: 4.46%\n",
      "Epoch 10: Train Loss: 3.9816, Train Acc: 5.25%, Val Loss: 4.3935, Val Acc: 1.79%\n",
      "Epoch 11: Train Loss: 3.9657, Train Acc: 6.03%, Val Loss: 4.3677, Val Acc: 0.89%\n",
      "Epoch 12: Train Loss: 3.9015, Train Acc: 6.58%, Val Loss: 4.3601, Val Acc: 1.79%\n",
      "Epoch 13: Train Loss: 3.8286, Train Acc: 6.92%, Val Loss: 4.4239, Val Acc: 3.57%\n",
      "Epoch 14: Train Loss: 3.7847, Train Acc: 7.70%, Val Loss: 4.4136, Val Acc: 1.79%\n",
      "Epoch 15: Train Loss: 3.7591, Train Acc: 6.14%, Val Loss: 4.4378, Val Acc: 1.79%\n",
      "Epoch 16: Train Loss: 3.7281, Train Acc: 9.82%, Val Loss: 4.4171, Val Acc: 2.68%\n",
      "Epoch 17: Train Loss: 3.7024, Train Acc: 7.37%, Val Loss: 4.4453, Val Acc: 1.79%\n",
      "Epoch 18: Train Loss: 3.6532, Train Acc: 8.82%, Val Loss: 4.4330, Val Acc: 1.79%\n",
      "Epoch 19: Train Loss: 3.6541, Train Acc: 8.37%, Val Loss: 4.4153, Val Acc: 1.79%\n",
      "Epoch 20: Train Loss: 3.6208, Train Acc: 9.26%, Val Loss: 4.4339, Val Acc: 1.79%\n",
      "Epoch 21: Train Loss: 3.5906, Train Acc: 10.16%, Val Loss: 4.4414, Val Acc: 3.57%\n",
      "Epoch 22: Train Loss: 3.5371, Train Acc: 11.72%, Val Loss: 4.4889, Val Acc: 2.68%\n",
      "Epoch 23: Train Loss: 3.4909, Train Acc: 11.72%, Val Loss: 4.5677, Val Acc: 3.57%\n",
      "Epoch 24: Train Loss: 3.4848, Train Acc: 11.61%, Val Loss: 4.4693, Val Acc: 1.79%\n",
      "Epoch 25: Train Loss: 3.4371, Train Acc: 12.39%, Val Loss: 4.5159, Val Acc: 4.46%\n",
      "Epoch 26: Train Loss: 3.4204, Train Acc: 11.61%, Val Loss: 4.4238, Val Acc: 1.79%\n",
      "Epoch 27: Train Loss: 3.4565, Train Acc: 9.04%, Val Loss: 4.5513, Val Acc: 3.57%\n",
      "Epoch 28: Train Loss: 3.3761, Train Acc: 12.50%, Val Loss: 4.4654, Val Acc: 3.57%\n",
      "Epoch 29: Train Loss: 3.3322, Train Acc: 13.95%, Val Loss: 4.4857, Val Acc: 4.46%\n",
      "Epoch 30: Train Loss: 3.3039, Train Acc: 12.17%, Val Loss: 4.5334, Val Acc: 4.46%\n",
      "Epoch 31: Train Loss: 3.2915, Train Acc: 14.40%, Val Loss: 4.5079, Val Acc: 3.57%\n",
      "Epoch 32: Train Loss: 3.2434, Train Acc: 12.95%, Val Loss: 4.4824, Val Acc: 1.79%\n",
      "Epoch 33: Train Loss: 3.2459, Train Acc: 14.84%, Val Loss: 4.5518, Val Acc: 3.57%\n",
      "Epoch 34: Train Loss: 3.2638, Train Acc: 14.17%, Val Loss: 4.6203, Val Acc: 7.14%\n",
      "Epoch 35: Train Loss: 3.2102, Train Acc: 15.62%, Val Loss: 4.5440, Val Acc: 3.57%\n",
      "Epoch 36: Train Loss: 3.1445, Train Acc: 17.30%, Val Loss: 4.6465, Val Acc: 2.68%\n",
      "Epoch 37: Train Loss: 3.1436, Train Acc: 16.96%, Val Loss: 4.6230, Val Acc: 2.68%\n",
      "Epoch 38: Train Loss: 3.1531, Train Acc: 15.96%, Val Loss: 4.6494, Val Acc: 2.68%\n",
      "Epoch 39: Train Loss: 3.1518, Train Acc: 15.18%, Val Loss: 4.6004, Val Acc: 5.36%\n",
      "Epoch 40: Train Loss: 3.0954, Train Acc: 18.30%, Val Loss: 4.6625, Val Acc: 2.68%\n",
      "Epoch 41: Train Loss: 3.1137, Train Acc: 16.07%, Val Loss: 4.5651, Val Acc: 2.68%\n",
      "Epoch 42: Train Loss: 3.0227, Train Acc: 16.85%, Val Loss: 4.6064, Val Acc: 6.25%\n",
      "Epoch 43: Train Loss: 3.0275, Train Acc: 18.08%, Val Loss: 4.5535, Val Acc: 5.36%\n",
      "Epoch 44: Train Loss: 3.0201, Train Acc: 17.30%, Val Loss: 4.5621, Val Acc: 5.36%\n",
      "Epoch 45: Train Loss: 3.0160, Train Acc: 18.75%, Val Loss: 4.8365, Val Acc: 2.68%\n",
      "Epoch 46: Train Loss: 3.0089, Train Acc: 17.97%, Val Loss: 4.6852, Val Acc: 4.46%\n",
      "Epoch 47: Train Loss: 2.9590, Train Acc: 19.20%, Val Loss: 4.6722, Val Acc: 3.57%\n",
      "Epoch 48: Train Loss: 2.9272, Train Acc: 18.19%, Val Loss: 4.7206, Val Acc: 1.79%\n",
      "Epoch 49: Train Loss: 2.8628, Train Acc: 20.98%, Val Loss: 4.7283, Val Acc: 4.46%\n",
      "Epoch 50: Train Loss: 2.9558, Train Acc: 17.41%, Val Loss: 4.6705, Val Acc: 3.57%\n",
      "Validation Loss: 3.5714\n",
      "Training with parameters: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'weight_decay': 0.0001}\n",
      "Epoch 1: Train Loss: 5.0653, Train Acc: 1.34%, Val Loss: 4.5951, Val Acc: 2.68%\n",
      "Epoch 2: Train Loss: 4.5587, Train Acc: 2.79%, Val Loss: 4.5893, Val Acc: 0.00%\n",
      "Epoch 3: Train Loss: 4.4463, Train Acc: 2.34%, Val Loss: 4.5197, Val Acc: 0.89%\n",
      "Epoch 4: Train Loss: 4.3131, Train Acc: 3.79%, Val Loss: 4.4475, Val Acc: 0.00%\n",
      "Epoch 5: Train Loss: 4.1813, Train Acc: 3.01%, Val Loss: 4.4220, Val Acc: 1.79%\n",
      "Epoch 6: Train Loss: 4.1177, Train Acc: 3.79%, Val Loss: 4.4296, Val Acc: 2.68%\n",
      "Epoch 7: Train Loss: 4.0836, Train Acc: 4.46%, Val Loss: 4.4198, Val Acc: 2.68%\n",
      "Epoch 8: Train Loss: 4.0731, Train Acc: 5.02%, Val Loss: 4.4223, Val Acc: 1.79%\n",
      "Epoch 9: Train Loss: 4.0432, Train Acc: 4.35%, Val Loss: 4.4326, Val Acc: 0.89%\n",
      "Epoch 10: Train Loss: 3.9928, Train Acc: 4.58%, Val Loss: 4.3963, Val Acc: 1.79%\n",
      "Epoch 11: Train Loss: 3.9450, Train Acc: 5.02%, Val Loss: 4.3560, Val Acc: 4.46%\n",
      "Epoch 12: Train Loss: 3.8796, Train Acc: 4.58%, Val Loss: 4.4444, Val Acc: 1.79%\n",
      "Epoch 13: Train Loss: 3.8551, Train Acc: 6.92%, Val Loss: 4.3697, Val Acc: 5.36%\n",
      "Epoch 14: Train Loss: 3.7985, Train Acc: 6.36%, Val Loss: 4.4015, Val Acc: 1.79%\n",
      "Epoch 15: Train Loss: 3.7811, Train Acc: 7.03%, Val Loss: 4.3756, Val Acc: 3.57%\n",
      "Epoch 16: Train Loss: 3.7425, Train Acc: 6.81%, Val Loss: 4.3999, Val Acc: 2.68%\n",
      "Epoch 17: Train Loss: 3.7373, Train Acc: 8.26%, Val Loss: 4.4377, Val Acc: 4.46%\n",
      "Epoch 18: Train Loss: 3.7197, Train Acc: 7.70%, Val Loss: 4.3899, Val Acc: 4.46%\n",
      "Epoch 19: Train Loss: 3.6637, Train Acc: 8.59%, Val Loss: 4.3902, Val Acc: 5.36%\n",
      "Epoch 20: Train Loss: 3.6485, Train Acc: 9.15%, Val Loss: 4.3985, Val Acc: 5.36%\n",
      "Epoch 21: Train Loss: 3.6440, Train Acc: 7.92%, Val Loss: 4.3693, Val Acc: 6.25%\n",
      "Epoch 22: Train Loss: 3.5982, Train Acc: 9.38%, Val Loss: 4.3240, Val Acc: 7.14%\n",
      "Epoch 23: Train Loss: 3.5510, Train Acc: 11.38%, Val Loss: 4.3736, Val Acc: 8.04%\n",
      "Epoch 24: Train Loss: 3.5384, Train Acc: 10.49%, Val Loss: 4.4041, Val Acc: 5.36%\n",
      "Epoch 25: Train Loss: 3.5126, Train Acc: 9.04%, Val Loss: 4.3540, Val Acc: 3.57%\n",
      "Epoch 26: Train Loss: 3.4553, Train Acc: 11.27%, Val Loss: 4.4135, Val Acc: 5.36%\n",
      "Epoch 27: Train Loss: 3.4388, Train Acc: 11.38%, Val Loss: 4.3906, Val Acc: 3.57%\n",
      "Epoch 28: Train Loss: 3.4294, Train Acc: 12.61%, Val Loss: 4.4400, Val Acc: 4.46%\n",
      "Epoch 29: Train Loss: 3.3609, Train Acc: 12.50%, Val Loss: 4.3092, Val Acc: 9.82%\n",
      "Epoch 30: Train Loss: 3.3607, Train Acc: 12.28%, Val Loss: 4.4632, Val Acc: 6.25%\n",
      "Epoch 31: Train Loss: 3.3513, Train Acc: 12.83%, Val Loss: 4.4939, Val Acc: 3.57%\n",
      "Epoch 32: Train Loss: 3.3251, Train Acc: 14.40%, Val Loss: 4.4620, Val Acc: 7.14%\n",
      "Epoch 33: Train Loss: 3.3216, Train Acc: 15.18%, Val Loss: 4.4354, Val Acc: 6.25%\n",
      "Epoch 34: Train Loss: 3.3052, Train Acc: 13.28%, Val Loss: 4.3517, Val Acc: 6.25%\n",
      "Epoch 35: Train Loss: 3.2964, Train Acc: 14.84%, Val Loss: 4.4526, Val Acc: 7.14%\n",
      "Epoch 36: Train Loss: 3.2685, Train Acc: 13.50%, Val Loss: 4.4832, Val Acc: 3.57%\n",
      "Epoch 37: Train Loss: 3.2110, Train Acc: 13.06%, Val Loss: 4.3895, Val Acc: 8.04%\n",
      "Epoch 38: Train Loss: 3.1517, Train Acc: 15.85%, Val Loss: 4.3556, Val Acc: 8.04%\n",
      "Epoch 39: Train Loss: 3.2147, Train Acc: 16.85%, Val Loss: 4.3444, Val Acc: 7.14%\n",
      "Epoch 40: Train Loss: 3.2019, Train Acc: 16.85%, Val Loss: 4.4405, Val Acc: 7.14%\n",
      "Epoch 41: Train Loss: 3.1807, Train Acc: 17.19%, Val Loss: 4.4735, Val Acc: 8.04%\n",
      "Epoch 42: Train Loss: 3.1472, Train Acc: 16.63%, Val Loss: 4.4154, Val Acc: 6.25%\n",
      "Epoch 43: Train Loss: 3.1218, Train Acc: 17.75%, Val Loss: 4.4800, Val Acc: 5.36%\n",
      "Epoch 44: Train Loss: 3.0530, Train Acc: 19.75%, Val Loss: 4.3617, Val Acc: 6.25%\n",
      "Epoch 45: Train Loss: 3.0502, Train Acc: 20.87%, Val Loss: 4.4936, Val Acc: 5.36%\n",
      "Epoch 46: Train Loss: 3.0232, Train Acc: 18.64%, Val Loss: 4.4162, Val Acc: 8.04%\n",
      "Epoch 47: Train Loss: 3.0323, Train Acc: 17.30%, Val Loss: 4.5281, Val Acc: 8.93%\n",
      "Epoch 48: Train Loss: 3.0713, Train Acc: 15.40%, Val Loss: 4.4477, Val Acc: 8.93%\n",
      "Epoch 49: Train Loss: 2.9980, Train Acc: 19.75%, Val Loss: 4.5083, Val Acc: 5.36%\n",
      "Epoch 50: Train Loss: 3.0087, Train Acc: 19.31%, Val Loss: 4.6640, Val Acc: 4.46%\n",
      "Validation Loss: 4.4643\n",
      "Training with parameters: {'dropout_rate': 0.5, 'learning_rate': 0.0005, 'weight_decay': 1e-05}\n",
      "Epoch 1: Train Loss: 4.8393, Train Acc: 0.45%, Val Loss: 4.5998, Val Acc: 1.79%\n",
      "Epoch 2: Train Loss: 4.5710, Train Acc: 1.67%, Val Loss: 4.5921, Val Acc: 1.79%\n",
      "Epoch 3: Train Loss: 4.4641, Train Acc: 3.24%, Val Loss: 4.5563, Val Acc: 0.89%\n",
      "Epoch 4: Train Loss: 4.3523, Train Acc: 3.35%, Val Loss: 4.5334, Val Acc: 0.89%\n",
      "Epoch 5: Train Loss: 4.2476, Train Acc: 3.35%, Val Loss: 4.5105, Val Acc: 0.89%\n",
      "Epoch 6: Train Loss: 4.1456, Train Acc: 4.35%, Val Loss: 4.4815, Val Acc: 0.00%\n",
      "Epoch 7: Train Loss: 4.0979, Train Acc: 5.47%, Val Loss: 4.4525, Val Acc: 1.79%\n",
      "Epoch 8: Train Loss: 4.0218, Train Acc: 5.80%, Val Loss: 4.4653, Val Acc: 0.89%\n",
      "Epoch 9: Train Loss: 3.9440, Train Acc: 7.25%, Val Loss: 4.4460, Val Acc: 0.89%\n",
      "Epoch 10: Train Loss: 3.9455, Train Acc: 6.92%, Val Loss: 4.4598, Val Acc: 2.68%\n",
      "Epoch 11: Train Loss: 3.8852, Train Acc: 6.81%, Val Loss: 4.4559, Val Acc: 3.57%\n",
      "Epoch 12: Train Loss: 3.8462, Train Acc: 7.81%, Val Loss: 4.4104, Val Acc: 4.46%\n",
      "Epoch 13: Train Loss: 3.8274, Train Acc: 7.92%, Val Loss: 4.4061, Val Acc: 1.79%\n",
      "Epoch 14: Train Loss: 3.7516, Train Acc: 9.93%, Val Loss: 4.4117, Val Acc: 4.46%\n",
      "Epoch 15: Train Loss: 3.7492, Train Acc: 9.71%, Val Loss: 4.4277, Val Acc: 0.89%\n",
      "Epoch 16: Train Loss: 3.6764, Train Acc: 11.94%, Val Loss: 4.4411, Val Acc: 2.68%\n",
      "Epoch 17: Train Loss: 3.6271, Train Acc: 9.15%, Val Loss: 4.4328, Val Acc: 3.57%\n",
      "Epoch 18: Train Loss: 3.5959, Train Acc: 10.27%, Val Loss: 4.4466, Val Acc: 0.89%\n",
      "Epoch 19: Train Loss: 3.5158, Train Acc: 12.39%, Val Loss: 4.4422, Val Acc: 3.57%\n",
      "Epoch 20: Train Loss: 3.4756, Train Acc: 13.73%, Val Loss: 4.4262, Val Acc: 2.68%\n",
      "Epoch 21: Train Loss: 3.4229, Train Acc: 13.28%, Val Loss: 4.4542, Val Acc: 3.57%\n",
      "Epoch 22: Train Loss: 3.3578, Train Acc: 16.41%, Val Loss: 4.4612, Val Acc: 4.46%\n",
      "Epoch 23: Train Loss: 3.3478, Train Acc: 16.74%, Val Loss: 4.4992, Val Acc: 4.46%\n",
      "Epoch 24: Train Loss: 3.2888, Train Acc: 15.18%, Val Loss: 4.3970, Val Acc: 5.36%\n",
      "Epoch 25: Train Loss: 3.2523, Train Acc: 16.29%, Val Loss: 4.4429, Val Acc: 2.68%\n",
      "Epoch 26: Train Loss: 3.1688, Train Acc: 17.52%, Val Loss: 4.4541, Val Acc: 5.36%\n",
      "Epoch 27: Train Loss: 3.1482, Train Acc: 19.87%, Val Loss: 4.4855, Val Acc: 7.14%\n",
      "Epoch 28: Train Loss: 3.1366, Train Acc: 18.64%, Val Loss: 4.3799, Val Acc: 6.25%\n",
      "Epoch 29: Train Loss: 3.1037, Train Acc: 19.64%, Val Loss: 4.4345, Val Acc: 7.14%\n",
      "Epoch 30: Train Loss: 3.0487, Train Acc: 20.31%, Val Loss: 4.4305, Val Acc: 4.46%\n",
      "Epoch 31: Train Loss: 2.9834, Train Acc: 22.43%, Val Loss: 4.4338, Val Acc: 2.68%\n",
      "Epoch 32: Train Loss: 2.9454, Train Acc: 20.42%, Val Loss: 4.4760, Val Acc: 7.14%\n",
      "Epoch 33: Train Loss: 2.8869, Train Acc: 21.65%, Val Loss: 4.4373, Val Acc: 7.14%\n",
      "Epoch 34: Train Loss: 2.8817, Train Acc: 21.88%, Val Loss: 4.5036, Val Acc: 6.25%\n",
      "Epoch 35: Train Loss: 2.8541, Train Acc: 25.11%, Val Loss: 4.4670, Val Acc: 8.93%\n",
      "Epoch 36: Train Loss: 2.8243, Train Acc: 22.99%, Val Loss: 4.4152, Val Acc: 8.93%\n",
      "Epoch 37: Train Loss: 2.7798, Train Acc: 24.55%, Val Loss: 4.3889, Val Acc: 8.04%\n",
      "Epoch 38: Train Loss: 2.7564, Train Acc: 27.23%, Val Loss: 4.5023, Val Acc: 5.36%\n",
      "Epoch 39: Train Loss: 2.7156, Train Acc: 27.79%, Val Loss: 4.6200, Val Acc: 6.25%\n",
      "Epoch 40: Train Loss: 2.6666, Train Acc: 27.46%, Val Loss: 4.5390, Val Acc: 6.25%\n",
      "Epoch 41: Train Loss: 2.6149, Train Acc: 29.80%, Val Loss: 4.5704, Val Acc: 7.14%\n",
      "Epoch 42: Train Loss: 2.5947, Train Acc: 28.01%, Val Loss: 4.5290, Val Acc: 4.46%\n",
      "Epoch 43: Train Loss: 2.5453, Train Acc: 30.69%, Val Loss: 4.4665, Val Acc: 7.14%\n",
      "Epoch 44: Train Loss: 2.5829, Train Acc: 28.24%, Val Loss: 4.6139, Val Acc: 9.82%\n",
      "Epoch 45: Train Loss: 2.4806, Train Acc: 30.02%, Val Loss: 4.6353, Val Acc: 8.93%\n",
      "Epoch 46: Train Loss: 2.4942, Train Acc: 31.14%, Val Loss: 4.5237, Val Acc: 8.93%\n",
      "Epoch 47: Train Loss: 2.4812, Train Acc: 30.36%, Val Loss: 4.5631, Val Acc: 7.14%\n",
      "Epoch 48: Train Loss: 2.4800, Train Acc: 30.25%, Val Loss: 4.7161, Val Acc: 8.04%\n",
      "Epoch 49: Train Loss: 2.4722, Train Acc: 30.69%, Val Loss: 4.5999, Val Acc: 6.25%\n",
      "Epoch 50: Train Loss: 2.3930, Train Acc: 35.16%, Val Loss: 4.7193, Val Acc: 10.71%\n",
      "Validation Loss: 10.7143\n",
      "Training with parameters: {'dropout_rate': 0.5, 'learning_rate': 0.0005, 'weight_decay': 0.0001}\n",
      "Epoch 1: Train Loss: 4.8570, Train Acc: 1.34%, Val Loss: 4.6050, Val Acc: 0.89%\n",
      "Epoch 2: Train Loss: 4.5172, Train Acc: 1.90%, Val Loss: 4.4973, Val Acc: 0.89%\n",
      "Epoch 3: Train Loss: 4.3860, Train Acc: 2.68%, Val Loss: 4.4588, Val Acc: 1.79%\n",
      "Epoch 4: Train Loss: 4.2330, Train Acc: 4.35%, Val Loss: 4.3924, Val Acc: 1.79%\n",
      "Epoch 5: Train Loss: 4.1804, Train Acc: 5.36%, Val Loss: 4.3706, Val Acc: 0.89%\n",
      "Epoch 6: Train Loss: 4.0915, Train Acc: 4.46%, Val Loss: 4.4016, Val Acc: 0.89%\n",
      "Epoch 7: Train Loss: 4.0171, Train Acc: 5.80%, Val Loss: 4.4469, Val Acc: 0.00%\n",
      "Epoch 8: Train Loss: 3.9480, Train Acc: 6.14%, Val Loss: 4.4157, Val Acc: 0.89%\n",
      "Epoch 9: Train Loss: 3.8957, Train Acc: 6.70%, Val Loss: 4.3966, Val Acc: 3.57%\n",
      "Epoch 10: Train Loss: 3.8301, Train Acc: 7.25%, Val Loss: 4.3829, Val Acc: 2.68%\n",
      "Epoch 11: Train Loss: 3.7920, Train Acc: 8.71%, Val Loss: 4.3723, Val Acc: 2.68%\n",
      "Epoch 12: Train Loss: 3.7354, Train Acc: 9.04%, Val Loss: 4.3820, Val Acc: 4.46%\n",
      "Epoch 13: Train Loss: 3.6597, Train Acc: 11.38%, Val Loss: 4.4623, Val Acc: 3.57%\n",
      "Epoch 14: Train Loss: 3.5900, Train Acc: 11.50%, Val Loss: 4.3821, Val Acc: 2.68%\n",
      "Epoch 15: Train Loss: 3.5549, Train Acc: 12.17%, Val Loss: 4.3287, Val Acc: 6.25%\n",
      "Epoch 16: Train Loss: 3.5068, Train Acc: 12.61%, Val Loss: 4.4153, Val Acc: 3.57%\n",
      "Epoch 17: Train Loss: 3.4123, Train Acc: 14.62%, Val Loss: 4.3557, Val Acc: 4.46%\n",
      "Epoch 18: Train Loss: 3.3692, Train Acc: 15.51%, Val Loss: 4.4194, Val Acc: 5.36%\n",
      "Epoch 19: Train Loss: 3.3261, Train Acc: 14.29%, Val Loss: 4.3651, Val Acc: 4.46%\n",
      "Epoch 20: Train Loss: 3.2766, Train Acc: 15.40%, Val Loss: 4.4001, Val Acc: 5.36%\n",
      "Epoch 21: Train Loss: 3.2772, Train Acc: 15.40%, Val Loss: 4.4337, Val Acc: 2.68%\n",
      "Epoch 22: Train Loss: 3.1653, Train Acc: 19.08%, Val Loss: 4.4119, Val Acc: 3.57%\n",
      "Epoch 23: Train Loss: 3.1235, Train Acc: 19.53%, Val Loss: 4.4711, Val Acc: 8.04%\n",
      "Epoch 24: Train Loss: 3.0566, Train Acc: 19.64%, Val Loss: 4.3926, Val Acc: 6.25%\n",
      "Epoch 25: Train Loss: 3.0688, Train Acc: 18.19%, Val Loss: 4.3900, Val Acc: 6.25%\n",
      "Epoch 26: Train Loss: 2.9722, Train Acc: 22.66%, Val Loss: 4.3862, Val Acc: 6.25%\n",
      "Epoch 27: Train Loss: 2.9243, Train Acc: 23.21%, Val Loss: 4.5156, Val Acc: 6.25%\n",
      "Epoch 28: Train Loss: 2.8838, Train Acc: 24.89%, Val Loss: 4.4278, Val Acc: 5.36%\n",
      "Epoch 29: Train Loss: 2.8672, Train Acc: 24.33%, Val Loss: 4.3714, Val Acc: 6.25%\n",
      "Epoch 30: Train Loss: 2.8052, Train Acc: 25.78%, Val Loss: 4.3788, Val Acc: 10.71%\n",
      "Epoch 31: Train Loss: 2.8020, Train Acc: 25.45%, Val Loss: 4.3277, Val Acc: 7.14%\n",
      "Epoch 32: Train Loss: 2.7205, Train Acc: 25.89%, Val Loss: 4.4481, Val Acc: 8.93%\n",
      "Epoch 33: Train Loss: 2.6749, Train Acc: 29.80%, Val Loss: 4.3736, Val Acc: 10.71%\n",
      "Epoch 34: Train Loss: 2.6127, Train Acc: 31.70%, Val Loss: 4.4506, Val Acc: 8.04%\n",
      "Epoch 35: Train Loss: 2.6289, Train Acc: 29.80%, Val Loss: 4.4727, Val Acc: 8.04%\n",
      "Epoch 36: Train Loss: 2.5727, Train Acc: 29.24%, Val Loss: 4.5521, Val Acc: 5.36%\n",
      "Epoch 37: Train Loss: 2.5260, Train Acc: 32.25%, Val Loss: 4.5083, Val Acc: 9.82%\n",
      "Epoch 38: Train Loss: 2.4562, Train Acc: 31.58%, Val Loss: 4.5495, Val Acc: 8.93%\n",
      "Epoch 39: Train Loss: 2.4586, Train Acc: 32.03%, Val Loss: 4.4696, Val Acc: 8.04%\n",
      "Epoch 40: Train Loss: 2.4520, Train Acc: 31.81%, Val Loss: 4.5391, Val Acc: 9.82%\n",
      "Epoch 41: Train Loss: 2.3592, Train Acc: 37.05%, Val Loss: 4.4966, Val Acc: 10.71%\n",
      "Epoch 42: Train Loss: 2.3510, Train Acc: 35.16%, Val Loss: 4.5016, Val Acc: 9.82%\n",
      "Epoch 43: Train Loss: 2.2661, Train Acc: 36.50%, Val Loss: 4.6369, Val Acc: 6.25%\n",
      "Epoch 44: Train Loss: 2.3438, Train Acc: 33.48%, Val Loss: 4.6137, Val Acc: 7.14%\n",
      "Epoch 45: Train Loss: 2.2222, Train Acc: 39.17%, Val Loss: 4.6420, Val Acc: 7.14%\n",
      "Epoch 46: Train Loss: 2.2265, Train Acc: 36.94%, Val Loss: 4.5692, Val Acc: 9.82%\n",
      "Epoch 47: Train Loss: 2.1821, Train Acc: 38.95%, Val Loss: 4.6984, Val Acc: 5.36%\n",
      "Epoch 48: Train Loss: 2.1967, Train Acc: 37.72%, Val Loss: 4.6502, Val Acc: 8.04%\n",
      "Epoch 49: Train Loss: 2.1034, Train Acc: 40.51%, Val Loss: 4.7991, Val Acc: 11.61%\n",
      "Epoch 50: Train Loss: 2.0842, Train Acc: 43.19%, Val Loss: 4.6416, Val Acc: 7.14%\n",
      "Validation Loss: 7.1429\n",
      "Training with parameters: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'weight_decay': 1e-05}\n",
      "Epoch 1: Train Loss: 4.6744, Train Acc: 0.89%, Val Loss: 4.6032, Val Acc: 0.89%\n",
      "Epoch 2: Train Loss: 4.5327, Train Acc: 2.46%, Val Loss: 4.6256, Val Acc: 0.89%\n",
      "Epoch 3: Train Loss: 4.4819, Train Acc: 2.90%, Val Loss: 4.6114, Val Acc: 0.89%\n",
      "Epoch 4: Train Loss: 4.4256, Train Acc: 3.24%, Val Loss: 4.5509, Val Acc: 1.79%\n",
      "Epoch 5: Train Loss: 4.3641, Train Acc: 3.46%, Val Loss: 4.5399, Val Acc: 0.89%\n",
      "Epoch 6: Train Loss: 4.2908, Train Acc: 4.24%, Val Loss: 4.5263, Val Acc: 0.89%\n",
      "Epoch 7: Train Loss: 4.2370, Train Acc: 4.58%, Val Loss: 4.5167, Val Acc: 1.79%\n",
      "Epoch 8: Train Loss: 4.1608, Train Acc: 6.03%, Val Loss: 4.4893, Val Acc: 0.89%\n",
      "Epoch 9: Train Loss: 4.1210, Train Acc: 4.80%, Val Loss: 4.4961, Val Acc: 1.79%\n",
      "Epoch 10: Train Loss: 4.0634, Train Acc: 5.80%, Val Loss: 4.4612, Val Acc: 0.89%\n",
      "Epoch 11: Train Loss: 4.0265, Train Acc: 6.47%, Val Loss: 4.4637, Val Acc: 0.89%\n",
      "Epoch 12: Train Loss: 3.9838, Train Acc: 7.25%, Val Loss: 4.4346, Val Acc: 1.79%\n",
      "Epoch 13: Train Loss: 3.9347, Train Acc: 7.70%, Val Loss: 4.4699, Val Acc: 0.89%\n",
      "Epoch 14: Train Loss: 3.9273, Train Acc: 8.15%, Val Loss: 4.4190, Val Acc: 1.79%\n",
      "Epoch 15: Train Loss: 3.8615, Train Acc: 9.26%, Val Loss: 4.4266, Val Acc: 1.79%\n",
      "Epoch 16: Train Loss: 3.8569, Train Acc: 9.49%, Val Loss: 4.4346, Val Acc: 0.00%\n",
      "Epoch 17: Train Loss: 3.8299, Train Acc: 9.82%, Val Loss: 4.4181, Val Acc: 0.89%\n",
      "Epoch 18: Train Loss: 3.7773, Train Acc: 11.27%, Val Loss: 4.4109, Val Acc: 1.79%\n",
      "Epoch 19: Train Loss: 3.7742, Train Acc: 11.16%, Val Loss: 4.4008, Val Acc: 0.89%\n",
      "Epoch 20: Train Loss: 3.7181, Train Acc: 13.17%, Val Loss: 4.3956, Val Acc: 0.89%\n",
      "Epoch 21: Train Loss: 3.7036, Train Acc: 10.71%, Val Loss: 4.3956, Val Acc: 0.89%\n",
      "Epoch 22: Train Loss: 3.6573, Train Acc: 12.83%, Val Loss: 4.3998, Val Acc: 2.68%\n",
      "Epoch 23: Train Loss: 3.6390, Train Acc: 14.17%, Val Loss: 4.4025, Val Acc: 0.89%\n",
      "Epoch 24: Train Loss: 3.5737, Train Acc: 15.74%, Val Loss: 4.3868, Val Acc: 1.79%\n",
      "Epoch 25: Train Loss: 3.5692, Train Acc: 14.40%, Val Loss: 4.3995, Val Acc: 1.79%\n",
      "Epoch 26: Train Loss: 3.5659, Train Acc: 13.84%, Val Loss: 4.3526, Val Acc: 1.79%\n",
      "Epoch 27: Train Loss: 3.5115, Train Acc: 15.96%, Val Loss: 4.3604, Val Acc: 2.68%\n",
      "Epoch 28: Train Loss: 3.4777, Train Acc: 15.85%, Val Loss: 4.3859, Val Acc: 1.79%\n",
      "Epoch 29: Train Loss: 3.4712, Train Acc: 15.74%, Val Loss: 4.3874, Val Acc: 2.68%\n",
      "Epoch 30: Train Loss: 3.4275, Train Acc: 16.18%, Val Loss: 4.3578, Val Acc: 1.79%\n",
      "Epoch 31: Train Loss: 3.4344, Train Acc: 16.18%, Val Loss: 4.3850, Val Acc: 1.79%\n",
      "Epoch 32: Train Loss: 3.3972, Train Acc: 18.53%, Val Loss: 4.3654, Val Acc: 4.46%\n",
      "Epoch 33: Train Loss: 3.3411, Train Acc: 20.09%, Val Loss: 4.3683, Val Acc: 2.68%\n",
      "Epoch 34: Train Loss: 3.3281, Train Acc: 19.42%, Val Loss: 4.3716, Val Acc: 2.68%\n",
      "Epoch 35: Train Loss: 3.3161, Train Acc: 19.53%, Val Loss: 4.3833, Val Acc: 3.57%\n",
      "Epoch 36: Train Loss: 3.2860, Train Acc: 19.98%, Val Loss: 4.3834, Val Acc: 4.46%\n",
      "Epoch 37: Train Loss: 3.2472, Train Acc: 20.31%, Val Loss: 4.3483, Val Acc: 5.36%\n",
      "Epoch 38: Train Loss: 3.2098, Train Acc: 21.88%, Val Loss: 4.3540, Val Acc: 4.46%\n",
      "Epoch 39: Train Loss: 3.2085, Train Acc: 21.88%, Val Loss: 4.3645, Val Acc: 3.57%\n",
      "Epoch 40: Train Loss: 3.1694, Train Acc: 21.43%, Val Loss: 4.3413, Val Acc: 6.25%\n",
      "Epoch 41: Train Loss: 3.1325, Train Acc: 23.77%, Val Loss: 4.3280, Val Acc: 6.25%\n",
      "Epoch 42: Train Loss: 3.0904, Train Acc: 26.23%, Val Loss: 4.3644, Val Acc: 5.36%\n",
      "Epoch 43: Train Loss: 3.1328, Train Acc: 22.32%, Val Loss: 4.3379, Val Acc: 5.36%\n",
      "Epoch 44: Train Loss: 3.0772, Train Acc: 24.55%, Val Loss: 4.3630, Val Acc: 5.36%\n",
      "Epoch 45: Train Loss: 3.0482, Train Acc: 26.23%, Val Loss: 4.3311, Val Acc: 6.25%\n",
      "Epoch 46: Train Loss: 3.0263, Train Acc: 24.00%, Val Loss: 4.3309, Val Acc: 7.14%\n",
      "Epoch 47: Train Loss: 2.9752, Train Acc: 25.78%, Val Loss: 4.3146, Val Acc: 7.14%\n",
      "Epoch 48: Train Loss: 2.9561, Train Acc: 27.23%, Val Loss: 4.3724, Val Acc: 5.36%\n",
      "Epoch 49: Train Loss: 2.9754, Train Acc: 26.67%, Val Loss: 4.2984, Val Acc: 8.93%\n",
      "Epoch 50: Train Loss: 2.9282, Train Acc: 28.46%, Val Loss: 4.3318, Val Acc: 7.14%\n",
      "Validation Loss: 7.1429\n",
      "Training with parameters: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'weight_decay': 0.0001}\n",
      "Epoch 1: Train Loss: 4.6718, Train Acc: 0.67%, Val Loss: 4.6451, Val Acc: 0.89%\n",
      "Epoch 2: Train Loss: 4.5233, Train Acc: 3.46%, Val Loss: 4.6170, Val Acc: 0.89%\n",
      "Epoch 3: Train Loss: 4.4720, Train Acc: 2.57%, Val Loss: 4.5903, Val Acc: 0.89%\n",
      "Epoch 4: Train Loss: 4.4091, Train Acc: 3.24%, Val Loss: 4.5531, Val Acc: 0.89%\n",
      "Epoch 5: Train Loss: 4.3422, Train Acc: 3.91%, Val Loss: 4.5312, Val Acc: 1.79%\n",
      "Epoch 6: Train Loss: 4.2579, Train Acc: 6.03%, Val Loss: 4.5181, Val Acc: 0.89%\n",
      "Epoch 7: Train Loss: 4.2003, Train Acc: 6.47%, Val Loss: 4.4959, Val Acc: 0.89%\n",
      "Epoch 8: Train Loss: 4.1477, Train Acc: 6.14%, Val Loss: 4.4659, Val Acc: 2.68%\n",
      "Epoch 9: Train Loss: 4.0930, Train Acc: 6.03%, Val Loss: 4.4538, Val Acc: 3.57%\n",
      "Epoch 10: Train Loss: 4.0458, Train Acc: 7.48%, Val Loss: 4.4507, Val Acc: 1.79%\n",
      "Epoch 11: Train Loss: 3.9864, Train Acc: 8.15%, Val Loss: 4.4228, Val Acc: 2.68%\n",
      "Epoch 12: Train Loss: 3.9605, Train Acc: 6.70%, Val Loss: 4.4211, Val Acc: 0.89%\n",
      "Epoch 13: Train Loss: 3.8945, Train Acc: 10.27%, Val Loss: 4.4278, Val Acc: 1.79%\n",
      "Epoch 14: Train Loss: 3.8677, Train Acc: 9.82%, Val Loss: 4.3920, Val Acc: 3.57%\n",
      "Epoch 15: Train Loss: 3.8364, Train Acc: 9.60%, Val Loss: 4.4134, Val Acc: 4.46%\n",
      "Epoch 16: Train Loss: 3.8073, Train Acc: 10.16%, Val Loss: 4.4027, Val Acc: 2.68%\n",
      "Epoch 17: Train Loss: 3.7907, Train Acc: 10.04%, Val Loss: 4.3680, Val Acc: 4.46%\n",
      "Epoch 18: Train Loss: 3.7632, Train Acc: 11.61%, Val Loss: 4.3757, Val Acc: 3.57%\n",
      "Epoch 19: Train Loss: 3.7191, Train Acc: 13.06%, Val Loss: 4.3626, Val Acc: 3.57%\n",
      "Epoch 20: Train Loss: 3.6885, Train Acc: 12.83%, Val Loss: 4.4017, Val Acc: 6.25%\n",
      "Epoch 21: Train Loss: 3.6534, Train Acc: 12.72%, Val Loss: 4.3590, Val Acc: 3.57%\n",
      "Epoch 22: Train Loss: 3.6166, Train Acc: 14.40%, Val Loss: 4.3641, Val Acc: 4.46%\n",
      "Epoch 23: Train Loss: 3.5756, Train Acc: 15.18%, Val Loss: 4.3550, Val Acc: 8.04%\n",
      "Epoch 24: Train Loss: 3.5292, Train Acc: 14.84%, Val Loss: 4.3598, Val Acc: 5.36%\n",
      "Epoch 25: Train Loss: 3.5028, Train Acc: 16.74%, Val Loss: 4.3442, Val Acc: 5.36%\n",
      "Epoch 26: Train Loss: 3.5132, Train Acc: 14.96%, Val Loss: 4.3628, Val Acc: 6.25%\n",
      "Epoch 27: Train Loss: 3.4381, Train Acc: 18.19%, Val Loss: 4.3381, Val Acc: 3.57%\n",
      "Epoch 28: Train Loss: 3.4199, Train Acc: 19.98%, Val Loss: 4.3173, Val Acc: 7.14%\n",
      "Epoch 29: Train Loss: 3.4025, Train Acc: 18.30%, Val Loss: 4.3287, Val Acc: 6.25%\n",
      "Epoch 30: Train Loss: 3.3708, Train Acc: 19.42%, Val Loss: 4.3325, Val Acc: 6.25%\n",
      "Epoch 31: Train Loss: 3.3516, Train Acc: 19.64%, Val Loss: 4.3157, Val Acc: 3.57%\n",
      "Epoch 32: Train Loss: 3.2885, Train Acc: 20.42%, Val Loss: 4.3129, Val Acc: 8.04%\n",
      "Epoch 33: Train Loss: 3.2606, Train Acc: 20.42%, Val Loss: 4.3235, Val Acc: 4.46%\n",
      "Epoch 34: Train Loss: 3.2236, Train Acc: 20.98%, Val Loss: 4.3605, Val Acc: 6.25%\n",
      "Epoch 35: Train Loss: 3.2238, Train Acc: 23.66%, Val Loss: 4.3329, Val Acc: 4.46%\n",
      "Epoch 36: Train Loss: 3.1821, Train Acc: 22.32%, Val Loss: 4.3158, Val Acc: 7.14%\n",
      "Epoch 37: Train Loss: 3.1725, Train Acc: 22.32%, Val Loss: 4.3305, Val Acc: 7.14%\n",
      "Epoch 38: Train Loss: 3.1194, Train Acc: 25.00%, Val Loss: 4.3444, Val Acc: 5.36%\n",
      "Epoch 39: Train Loss: 3.0599, Train Acc: 27.46%, Val Loss: 4.3096, Val Acc: 6.25%\n",
      "Epoch 40: Train Loss: 3.0724, Train Acc: 23.88%, Val Loss: 4.3058, Val Acc: 7.14%\n",
      "Epoch 41: Train Loss: 3.0511, Train Acc: 25.56%, Val Loss: 4.2966, Val Acc: 5.36%\n",
      "Epoch 42: Train Loss: 3.0020, Train Acc: 26.79%, Val Loss: 4.3186, Val Acc: 7.14%\n",
      "Epoch 43: Train Loss: 2.9647, Train Acc: 29.13%, Val Loss: 4.3073, Val Acc: 8.93%\n",
      "Epoch 44: Train Loss: 2.9258, Train Acc: 30.92%, Val Loss: 4.2686, Val Acc: 9.82%\n",
      "Epoch 45: Train Loss: 2.9555, Train Acc: 26.90%, Val Loss: 4.2835, Val Acc: 7.14%\n",
      "Epoch 46: Train Loss: 2.8863, Train Acc: 28.46%, Val Loss: 4.2914, Val Acc: 8.04%\n",
      "Epoch 47: Train Loss: 2.8591, Train Acc: 30.80%, Val Loss: 4.2920, Val Acc: 6.25%\n",
      "Epoch 48: Train Loss: 2.8738, Train Acc: 29.58%, Val Loss: 4.2508, Val Acc: 6.25%\n",
      "Epoch 49: Train Loss: 2.8314, Train Acc: 30.69%, Val Loss: 4.3032, Val Acc: 8.04%\n",
      "Epoch 50: Train Loss: 2.7626, Train Acc: 33.59%, Val Loss: 4.2726, Val Acc: 7.14%\n",
      "Validation Loss: 7.1429\n",
      "Best model and parameters saved to: /content/drive/MyDrive/Colab Notebooks/AAI-521/Final Project/best_mod\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search for hyperparameters\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "best_params = {}\n",
    "\n",
    "# Define the device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Training with parameters: {params}\")\n",
    "\n",
    "    # Instantiate the model inside the loop with num_classes\n",
    "    model = FCNNBaseline(input_dim=90 * 258, num_classes=num_classes)  # Pass num_classes here\n",
    "    model = model.to(device)  # Move model to the selected device (CPU/GPU)\n",
    "\n",
    "    # Train and evaluate the model, and get the validation loss\n",
    "    val_loss = train_and_evaluate_model(\n",
    "        learning_rate=params['learning_rate'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        weight_decay=params['weight_decay'],\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Save the best model and parameters based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_params = params\n",
    "        best_model = model  # Save the model with the best validation loss\n",
    "\n",
    "# Save the best model and parameters\n",
    "final_best_model_path = '/content/drive/MyDrive/Colab Notebooks/AAI-521/Final Project/best_mod'\n",
    "os.makedirs(final_best_model_path, exist_ok=True)\n",
    "\n",
    "# Save the best model's state_dict\n",
    "torch.save(best_model.state_dict(), os.path.join(final_best_model_path, 'best_model_overall_FCNN.pth'))\n",
    "\n",
    "# Save the best hyperparameters as a JSON file\n",
    "best_params_path = os.path.join(final_best_model_path, 'best_model_params_FCNN.json')\n",
    "with open(best_params_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'learning_rate': best_params['learning_rate'],\n",
    "        'dropout_rate': best_params['dropout_rate'],\n",
    "        'weight_decay': best_params['weight_decay'],\n",
    "        'validation_loss': best_val_loss  # Best validation loss\n",
    "    }, f)\n",
    "\n",
    "print(f\"Best model and parameters saved to: {final_best_model_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1733472544976,
     "user": {
      "displayName": "Aaron Ramirez",
      "userId": "09089953805173967437"
     },
     "user_tz": -540
    },
    "id": "5ee5GZBt8NU4",
    "outputId": "afac6f55-305c-4b65-ded7-777dfd7288a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.0001, 'dropout_rate': 0.3, 'weight_decay': 0.0001, 'validation_loss': 3.571428571428571}\n",
      "Test Loss: 4.596932888031006\n",
      "Test Accuracy: 3.571428571428571%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-b92ba53e7f4e>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(final_best_model_path, 'best_model_overall_FCNN.pth')))  # Load the saved weights\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Define the path to your saved best model and parameters\n",
    "final_best_model_path = '/content/drive/MyDrive/Colab Notebooks/AAI-521/Final Project/best_mod'\n",
    "\n",
    "# Load the best hyperparameters (from the saved JSON file)\n",
    "best_params_path = os.path.join(final_best_model_path, 'best_model_params_FCNN.json')\n",
    "\n",
    "with open(best_params_path, 'r') as file:\n",
    "    best_params = json.load(file)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Load the best model\n",
    "model = FCNNBaseline(input_dim=90 * 258, num_classes=100)  # Initialize model (already defined in the code)\n",
    "model.load_state_dict(torch.load(os.path.join(final_best_model_path, 'best_model_overall_FCNN.pth')))  # Load the saved weights\n",
    "model = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))  # Move model to the selected device (CPU/GPU)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Prepare the test data (ensure X_test and y_test are tensors)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Reshape X_test_tensor to match the expected input size: [batch_size, 90 * 258]\n",
    "X_test_tensor = X_test_tensor.view(X_test_tensor.size(0), -1)  # Flatten each sample into a 1D vector\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "with torch.no_grad():  # Disable gradient calculation during evaluation\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Convert one-hot labels to class indices and compare\n",
    "    true_labels = torch.argmax(y_test_tensor, dim=1)  # Convert one-hot labels to class indices\n",
    "\n",
    "    correct_preds = (predicted == true_labels).sum().item()\n",
    "    total_preds = y_test_tensor.size(0)\n",
    "\n",
    "    test_accuracy = correct_preds / total_preds * 100\n",
    "\n",
    "    # CrossEntropyLoss expects the target to be of type torch.long (class indices) and outputs to be logits\n",
    "    test_loss = nn.CrossEntropyLoss()(outputs, true_labels).item()\n",
    "\n",
    "# Print the test results\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}%\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
